# CardEverything æ•°æ®è¿ç§»ç­–ç•¥æ–‡æ¡£

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

- **æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-01-13
- **æœ€åæ›´æ–°**: 2025-01-13
- **ä½œè€…**: Database-Architect
- **é€‚ç”¨èŒƒå›´**: CardEverything åŒæ­¥æœåŠ¡é‡æ„é¡¹ç›®
- **ä¾èµ–ä»»åŠ¡**: W1-T002 æ•°æ®å­˜å‚¨æ¶æ„åˆ†æ, W1-T006 ç»Ÿä¸€æ¶æ„è®¾è®¡
- **ä»»åŠ¡çŠ¶æ€**: W1-T008 è¿›è¡Œä¸­

## ğŸ¯ æ‰§è¡Œæ‘˜è¦

æœ¬æ•°æ®è¿ç§»ç­–ç•¥æ–‡æ¡£ä¸ºCardEverythingåŒæ­¥æœåŠ¡é‡æ„é¡¹ç›®æä¾›äº†å®Œæ•´çš„æ•°æ®è¿ç§»è§£å†³æ–¹æ¡ˆã€‚åŸºäºW1-T002æ•°æ®å­˜å‚¨æ¶æ„åˆ†æå’ŒW1-T006ç»Ÿä¸€æ¶æ„è®¾è®¡çš„æ·±å…¥åˆ†æï¼Œæˆ‘ä»¬è®¾è®¡äº†æ”¯æŒä¸‰é‡åŒæ­¥æœåŠ¡ç»Ÿä¸€çš„æ•°æ®è¿ç§»æ–¹æ¡ˆã€‚

### æ ¸å¿ƒç›®æ ‡
1. **æ¶æ„ç»Ÿä¸€**: å°†ä¸‰ä¸ªç‹¬ç«‹çš„åŒæ­¥æœåŠ¡ï¼ˆCloudSyncServiceã€OptimizedCloudSyncServiceã€UnifiedSyncServiceï¼‰ç»Ÿä¸€åˆ°å•ä¸€æ¶æ„
2. **é›¶åœæœºè¿ç§»**: ç¡®ä¿ç”¨æˆ·åœ¨è¿ç§»è¿‡ç¨‹ä¸­æ— æ„ŸçŸ¥æœåŠ¡ä¸­æ–­
3. **æ•°æ®ä¸€è‡´æ€§**: ä¿è¯IndexedDBæœ¬åœ°æ•°æ®ä¸Supabaseäº‘ç«¯æ•°æ®çš„å®Œå…¨ä¸€è‡´
4. **å‘åå…¼å®¹**: é€šè¿‡APIå…¼å®¹å±‚ç¡®ä¿ç°æœ‰UIç»„ä»¶æ— éœ€ä¿®æ”¹å³å¯å¹³æ»‘è¿ç§»
5. **æ€§èƒ½ä¼˜åŒ–**: è¿ç§»åå®ç°70-80%çš„æ€§èƒ½æå‡ç›®æ ‡

### è¿ç§»èŒƒå›´
- **æœ¬åœ°æ•°æ®åº“**: IndexedDB schemaç»Ÿä¸€å’Œä¼˜åŒ–
- **äº‘ç«¯æ•°æ®åº“**: Supabaseæ•°æ®æ¨¡å‹åŒæ­¥
- **åŒæ­¥æœºåˆ¶**: ç»Ÿä¸€åŒæ­¥é˜Ÿåˆ—å’Œå†²çªè§£å†³æœºåˆ¶
- **ç”¨æˆ·æ•°æ®**: å¡ç‰‡ã€æ–‡ä»¶å¤¹ã€æ ‡ç­¾ã€å›¾ç‰‡ç­‰æ ¸å¿ƒå®ä½“æ•°æ®

## ğŸ“Š ç°æœ‰æ•°æ®æ¶æ„åˆ†æ

### 1. æ•°æ®åº“æ–‡ä»¶å·®å¼‚åˆ†æ

#### 1.1 database.ts (å½“å‰ç»Ÿä¸€ç‰ˆæœ¬) - ç‰ˆæœ¬3
**æ ¸å¿ƒç‰¹æ€§ï¼š**
- **æ•°æ®åº“ç‰ˆæœ¬**: 3.0.0
- **è¡¨ç»“æ„**: 7ä¸ªæ ¸å¿ƒè¡¨ï¼ˆcards, folders, tags, images, syncQueue, settings, sessionsï¼‰
- **ç´¢å¼•ç­–ç•¥**: ä¼˜åŒ–çš„å¤åˆç´¢å¼•è®¾è®¡
- **åŒæ­¥æœºåˆ¶**: å®Œæ•´çš„syncVersionå’ŒpendingSyncå­—æ®µ
- **ç”¨æˆ·æ”¯æŒ**: å®Œæ•´çš„å¤šç”¨æˆ·æ”¯æŒ
- **å›¾ç‰‡ç®¡ç†**: ç‹¬ç«‹çš„DbImageå®ä½“ï¼Œæ”¯æŒå¤šç§å­˜å‚¨æ¨¡å¼

**å…³é”®æ•°æ®æ¨¡å‹ï¼š**
```typescript
interface DbCard extends SyncableEntity {
  searchVector?: string    // å…¨æ–‡æœç´¢ä¼˜åŒ–
  thumbnailUrl?: string    // ç¼©ç•¥å›¾æ”¯æŒ
  folderId?: string        // æ–‡ä»¶å¤¹å…³è”
}

interface DbImage {
  storageMode: 'indexeddb' | 'filesystem' | 'cloud'
  metadata: {              // å®Œæ•´çš„å…ƒæ•°æ®
    size: number
    width: number
    height: number
    format: string
    compressed: boolean
  }
}
```

#### 1.2 database-simple.ts (å·²ç§»é™¤ç‰ˆæœ¬) - ç‰ˆæœ¬1
**æ ¸å¿ƒç‰¹æ€§ï¼š**
- **æ•°æ®åº“ç‰ˆæœ¬**: 1.0.0
- **è¡¨ç»“æ„**: 5ä¸ªåŸºæœ¬è¡¨ï¼ˆç¼ºå°‘imageså’Œsessionsï¼‰
- **ç´¢å¼•ç­–ç•¥**: åŸºç¡€ç´¢å¼•ï¼Œç¼ºå°‘å¤åˆç´¢å¼•
- **åŒæ­¥æœºåˆ¶**: åŸºç¡€ç‰ˆæœ¬æ§åˆ¶
- **ç”¨æˆ·æ”¯æŒ**: åŸºç¡€ç”¨æˆ·å­—æ®µ
- **å›¾ç‰‡ç®¡ç†**: æ— ç‹¬ç«‹å›¾ç‰‡è¡¨

### 2. æ•°æ®æ¨¡å‹å†²çªè¯†åˆ«

#### 2.1 å­—æ®µå‘½åä¸ä¸€è‡´
| å®ä½“ | database.ts | database-simple.ts | ç»Ÿä¸€æ–¹æ¡ˆ |
|------|-------------|-------------------|----------|
| åŒæ­¥æ“ä½œ | `entity: 'card' \| 'folder' \| 'tag' \| 'image'` | `table: 'cards' \| 'folders' \| 'tags' \| 'images'` | ä½¿ç”¨entityå­—æ®µ |
| ç”¨æˆ·ID | `userId?: string` | `userId?: string` | ä¿æŒç°æœ‰å­—æ®µ |
| åŒæ­¥ç‰ˆæœ¬ | `syncVersion: number` | `syncVersion: number` | ä¿æŒç°æœ‰å­—æ®µ |

#### 2.2 æ•°æ®ç±»å‹å·®å¼‚
```typescript
// database.ts ä¸­çš„ SyncOperation
interface SyncOperation {
  entity: 'card' | 'folder' | 'tag' | 'image'  // å•æ•°å½¢å¼
  entityId: string                              // å®ä½“ID
  priority: 'high' | 'normal' | 'low'         // ä¼˜å…ˆçº§å­—æ®µ
}

// database-simple.ts ä¸­çš„ SyncOperation
interface LegacySyncOperation {
  table: 'cards' | 'folders' | 'tags' | 'images' // å¤æ•°å½¢å¼
  localId: string                              // æœ¬åœ°ID
  // ç¼ºå°‘ä¼˜å…ˆçº§å­—æ®µ
}
```

### 3. æ•°æ®é‡å’Œå¤æ‚åº¦è¯„ä¼°

#### 3.1 å½“å‰æ•°æ®è§„æ¨¡ä¼°ç®—
- **å¡ç‰‡æ•°é‡**: é¢„è®¡ 1,000-10,000 å¼ 
- **æ–‡ä»¶å¤¹æ•°é‡**: é¢„è®¡ 100-500 ä¸ª
- **æ ‡ç­¾æ•°é‡**: é¢„è®¡ 500-2,000 ä¸ª
- **å›¾ç‰‡æ•°é‡**: é¢„è®¡ 2,000-20,000 ä¸ª
- **æ€»æ•°æ®é‡**: é¢„è®¡ 100MB-1GB

#### 3.2 å¤æ‚åº¦è¯„ä¼°
- **å…³ç³»å¤æ‚åº¦**: ä¸­ç­‰ï¼ˆæ–‡ä»¶å¤¹å±‚çº§ã€æ ‡ç­¾å…³è”ï¼‰
- **æ•°æ®ä¾èµ–**: é«˜ï¼ˆå¡ç‰‡ä¾èµ–æ–‡ä»¶å¤¹ã€å›¾ç‰‡ä¾èµ–å¡ç‰‡ï¼‰
- **åŒæ­¥å¤æ‚åº¦**: é«˜ï¼ˆå¤šç‰ˆæœ¬ã€å¹¶å‘æ“ä½œï¼‰
- **è¿ç§»é£é™©**: ä¸­ç­‰ï¼ˆéœ€è¦ä¿æŒæ•°æ®ä¸€è‡´æ€§ï¼‰

### 4. ç»Ÿä¸€æ¶æ„ä¸‹çš„æ•°æ®è¿ç§»æŒ‘æˆ˜

#### 4.1 ä¸‰é‡åŒæ­¥æœåŠ¡ç»Ÿä¸€æŒ‘æˆ˜
åŸºäºW1-T006ç»Ÿä¸€æ¶æ„è®¾è®¡å’ŒW1-T002æ¶æ„åˆ†æï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºä»¥ä¸‹å…³é”®è¿ç§»æŒ‘æˆ˜ï¼š

| æŒ‘æˆ˜ç±»å‹ | æè¿° | é£é™©ç­‰çº§ | è§£å†³æ–¹æ¡ˆ |
|----------|------|----------|----------|
| **æ•°æ®æ¨¡å‹å·®å¼‚** | ä¸‰ä¸ªæœåŠ¡ä½¿ç”¨ä¸åŒçš„æ•°æ®ç»“æ„å’Œå­—æ®µå‘½å | ğŸŸ¡ ä¸­ç­‰ | ç»Ÿä¸€æ•°æ®æ¨¡å‹ï¼Œå»ºç«‹æ˜ å°„è¡¨ |
| **åŒæ­¥æœºåˆ¶å†²çª** | ä¸åŒæœåŠ¡çš„åŒæ­¥é˜Ÿåˆ—å’Œå†²çªè§£å†³æœºåˆ¶ä¸å…¼å®¹ | ğŸ”´ é«˜ | ç»Ÿä¸€åŒæ­¥å¼•æ“ï¼Œå…¼å®¹å±‚é€‚é… |
| **APIæ¥å£ä¸ç»Ÿä¸€** | ç°æœ‰UIç»„ä»¶ä¾èµ–ä¸åŒçš„åŒæ­¥æœåŠ¡API | ğŸŸ¡ ä¸­ç­‰ | APIå…¼å®¹å±‚é€‚é…å™¨ |
| **æ•°æ®ä¸€è‡´æ€§é—®é¢˜** | å¤šæœåŠ¡å¹¶è¡Œå¯èƒ½å¯¼è‡´æ•°æ®ä¸ä¸€è‡´ | ğŸ”´ é«˜ | å¼ºä¸€è‡´æ€§æ£€æŸ¥å’Œä¿®å¤æœºåˆ¶ |
| **æ€§èƒ½å½±å“** | è¿ç§»è¿‡ç¨‹å¯èƒ½å½±å“ç³»ç»Ÿæ€§èƒ½ | ğŸŸ¡ ä¸­ç­‰ | æ¸è¿›å¼è¿ç§»ï¼Œæ€§èƒ½ç›‘æ§ |

#### 4.2 åŸºäºç»Ÿä¸€æ¶æ„çš„æ•°æ®æ˜ å°„
æ ¹æ®ç»Ÿä¸€æ¶æ„è®¾è®¡ï¼ˆW1-T006ï¼‰ï¼Œå»ºç«‹æ•°æ®æ˜ å°„å…³ç³»ï¼š

```typescript
// ç»Ÿä¸€æ•°æ®æ¨¡å‹
interface UnifiedDataModel {
  // æ ¸å¿ƒå®ä½“
  cards: UnifiedCard[]
  folders: UnifiedFolder[]
  tags: UnifiedTag[]
  images: UnifiedImage[]

  // åŒæ­¥å…ƒæ•°æ®
  syncQueue: UnifiedSyncOperation[]
  syncState: UnifiedSyncState

  // ç”¨æˆ·æ•°æ®
  users: UnifiedUser[]
  userSettings: UnifiedUserSettings
}

// ç»Ÿä¸€å¡ç‰‡å®ä½“
interface UnifiedCard extends SyncableEntity {
  id: string
  userId: string
  frontContent: CardContent
  backContent: CardContent
  style: CardStyle
  folderId?: string
  tags: string[]
  images: string[]
  searchVector?: string
  thumbnailUrl?: string
  createdAt: Date
  updatedAt: Date
  syncVersion: number
  isDeleted: boolean
}
```

### 5. æ•°æ®ä¾èµ–å…³ç³»åˆ†æ

#### 5.1 æ ¸å¿ƒä¾èµ–é“¾
```
ç”¨æˆ· â†’ æ–‡ä»¶å¤¹ â†’ å¡ç‰‡ â†’ å›¾ç‰‡
  â†“        â†“       â†“
  è®¾ç½®     æ ‡ç­¾    åŒæ­¥é˜Ÿåˆ—
```

#### 4.2 è¿ç§»ä¼˜å…ˆçº§
1. **æœ€é«˜ä¼˜å…ˆçº§**: ç”¨æˆ·ä¼šè¯å’Œè®¾ç½®
2. **é«˜ä¼˜å…ˆçº§**: æ–‡ä»¶å¤¹ç»“æ„å’Œæ ‡ç­¾
3. **ä¸­ä¼˜å…ˆçº§**: å¡ç‰‡æ•°æ®
4. **ä½ä¼˜å…ˆçº§**: å›¾ç‰‡å’ŒåŒæ­¥é˜Ÿåˆ—

## ğŸ—ï¸ åŸºäºç»Ÿä¸€æ¶æ„çš„è¿ç§»ç­–ç•¥è®¾è®¡

åŸºäºW1-T006ç»Ÿä¸€æ¶æ„è®¾è®¡å’ŒAPIå…¼å®¹å±‚è®¾è®¡ï¼ˆW1-T007ï¼‰ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸‰é˜¶æ®µæ¸è¿›å¼è¿ç§»ç­–ç•¥ï¼š

### 1. é˜¶æ®µåˆ’åˆ†å’Œæ‰§è¡Œè·¯å¾„

#### 1.1 ç¬¬ä¸€é˜¶æ®µï¼šå…¼å®¹å±‚éƒ¨ç½² (Week 1-2)
**ç›®æ ‡**: éƒ¨ç½²APIå…¼å®¹å±‚ï¼Œç¡®ä¿ç°æœ‰åŠŸèƒ½æ­£å¸¸è¿è¡Œ

```typescript
// å…¼å®¹å±‚éƒ¨ç½²ç­–ç•¥
export class CompatibilityLayerDeployment {
  async deployCompatibilityLayer(): Promise<DeploymentResult> {
    const steps = [
      'éƒ¨ç½²SyncServiceAdapter',
      'é…ç½®è¿‡æ¸¡æ¨¡å¼ (transition mode)',
      'å»ºç«‹æœåŠ¡æ˜ å°„å…³ç³»',
      'å¯ç”¨APIå…¼å®¹æ€§æµ‹è¯•',
      'ç›‘æ§ç°æœ‰åŠŸèƒ½è¡¨ç°'
    ]

    const results = await this.executeDeploymentSteps(steps)

    return {
      success: results.every(r => r.success),
      compatibilityMode: 'transition',
      backwardCompatibility: true,
      performanceImpact: '< 5%',
      rollbackAvailable: true
    }
  }
}
```

#### 1.2 ç¬¬äºŒé˜¶æ®µï¼šæ•°æ®ç»Ÿä¸€è¿ç§» (Week 3-4)
**ç›®æ ‡**: ç»Ÿä¸€IndexedDBå’ŒSupabaseæ•°æ®æ¨¡å‹ï¼Œå®ç°æ— ç¼æ•°æ®åŒæ­¥

```typescript
// æ•°æ®ç»Ÿä¸€è¿ç§»ç­–ç•¥
export class DataUnificationMigration {
  async migrateToUnifiedSchema(): Promise<MigrationResult> {
    const migrationPlan = {
      // 1. IndexedDB Schemaå‡çº§
      indexedDbUpgrade: {
        version: '3.0.0 â†’ 4.0.0',
        changes: [
          'ç»Ÿä¸€å®ä½“å‘½åè§„èŒƒ',
          'æ·»åŠ sync_versionå­—æ®µ',
          'ä¼˜åŒ–ç´¢å¼•ç»“æ„',
          'å»ºç«‹æ•°æ®å…³è”å…³ç³»'
        ]
      },

      // 2. Supabaseæ•°æ®åŒæ­¥
      supabaseSync: {
        strategy: 'bidirectional',
        conflictResolution: 'last-write-wins',
        validationLevel: 'strict'
      },

      // 3. APIå…¼å®¹å±‚åˆ‡æ¢
      apiLayerTransition: {
        fromMode: 'transition',
        toMode: 'unified',
        rollbackPoint: true
      }
    }

    return await this.executeUnifiedMigration(migrationPlan)
  }
}
```

#### 1.3 ç¬¬ä¸‰é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–å’Œç¨³å®šåŒ– (Week 5-6)
**ç›®æ ‡**: ä¼˜åŒ–åŒæ­¥æ€§èƒ½ï¼Œå®ç°70-80%æ€§èƒ½æå‡ç›®æ ‡

```typescript
// æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
export class PerformanceOptimization {
  async optimizeSyncPerformance(): Promise<OptimizationResult> {
    const optimizations = [
      {
        type: 'cache',
        description: 'å®ç°æ™ºèƒ½ç¼“å­˜æœºåˆ¶',
        expectedImprovement: '30%'
      },
      {
        type: 'batching',
        description: 'æ‰¹é‡åŒæ­¥æ“ä½œä¼˜åŒ–',
        expectedImprovement: '25%'
      },
      {
        type: 'indexing',
        description: 'æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–',
        expectedImprovement: '15%'
      },
      {
        type: 'network',
        description: 'ç½‘ç»œè¯·æ±‚ä¼˜åŒ–',
        expectedImprovement: '10%'
      }
    ]

    const results = await this.applyOptimizations(optimizations)

    return {
      totalImprovement: this.calculateTotalImprovement(results),
      targetsAchieved: results.every(r => r.success),
      baselineMetrics: await this.captureBaselineMetrics(),
      optimizedMetrics: await this.captureOptimizedMetrics()
    }
  }
}
```

### 2. APIå…¼å®¹å±‚é›†æˆç­–ç•¥

#### 2.1 æ¸è¿›å¼APIè¿ç§»
åŸºäºAPIå…¼å®¹å±‚è®¾è®¡æ–‡æ¡£ï¼Œå®ç°æ— ç¼APIè¿ç§»ï¼š

```typescript
// APIå…¼å®¹å±‚é›†æˆ
export class APICompatibilityIntegration {
  async integrateWithMigration(): Promise<IntegrationResult> {
    // 1. æ¨¡å—åˆ«åé…ç½®
    await this.configureModuleAliases({
      '@/services/cloud-sync': '@/adapters/sync-service-adapter',
      '@/services/optimized-cloud-sync': '@/adapters/sync-service-adapter',
      '@/services/unified-sync-service': '@/adapters/sync-service-adapter'
    })

    // 2. Hooksé€‚é…å™¨éƒ¨ç½²
    await this.deployHooksAdapters({
      useCardsDb: 'compatible',
      useFoldersDb: 'compatible',
      useTagsDb: 'compatible'
    })

    // 3. çŠ¶æ€æŒ‡ç¤ºå™¨é€‚é…
    await this.adaptStatusIndicators({
      SyncStatusIndicator: 'unified',
      SyncProgressBar: 'enhanced'
    })

    return {
      apiCompatibility: '100%',
      componentMigration: '0%', // å¼€å§‹æ¸è¿›è¿ç§»
      performanceImpact: '< 10%',
      rollbackCapability: true
    }
  }
}
```

#### 2.2 ç»„ä»¶æ¸è¿›è¿ç§»ç­–ç•¥
```typescript
// ç»„ä»¶è¿ç§»ç®¡ç†
export class ComponentMigrationManager {
  async migrateComponentsGradually(): Promise<MigrationProgress> {
    const migrationOrder = [
      // ç¬¬ä¸€æ‰¹ï¼šä½é£é™©ç»„ä»¶
      { component: 'SyncStatusIndicator', risk: 'low', priority: 1 },
      { component: 'useCardsDb', risk: 'low', priority: 1 },

      // ç¬¬äºŒæ‰¹ï¼šä¸­é£é™©ç»„ä»¶
      { component: 'CardEditor', risk: 'medium', priority: 2 },
      { component: 'FolderManager', risk: 'medium', priority: 2 },

      // ç¬¬ä¸‰æ‰¹ï¼šé«˜é£é™©ç»„ä»¶
      { component: 'SyncEngine', risk: 'high', priority: 3 },
      { component: 'ConflictResolver', risk: 'high', priority: 3 }
    ]

    let progress = 0
    const totalComponents = migrationOrder.length

    for (const component of migrationOrder) {
      await this.migrateSingleComponent(component)
      progress = Math.round((migrationOrder.indexOf(component) + 1) / totalComponents * 100)

      // ç›‘æ§è¿ç§»æ•ˆæœ
      await this.monitorMigrationImpact(component)

      // å¦‚æœå‡ºç°é—®é¢˜ï¼Œæš‚åœè¿ç§»
      if (await this.detectMigrationIssues()) {
        await this.pauseMigration(component)
        break
      }
    }

    return { progress: `${progress}%`, migratedComponents: progress }
  }
}
```

### 3. æ•°æ®ä¸€è‡´æ€§ä¿éšœæœºåˆ¶

#### 3.1 å®æ—¶ä¸€è‡´æ€§æ£€æŸ¥
```typescript
// æ•°æ®ä¸€è‡´æ€§éªŒè¯
export class DataConsistencyValidator {
  async validateDataConsistency(): Promise<ConsistencyResult> {
    const checks = [
      {
        type: 'entity_count',
        description: 'æœ¬åœ°å’Œäº‘ç«¯å®ä½“æ•°é‡ä¸€è‡´æ€§',
        critical: true
      },
      {
        type: 'data_integrity',
        description: 'æ•°æ®å®Œæ•´æ€§å’Œå…³è”å…³ç³»æ£€æŸ¥',
        critical: true
      },
      {
        type: 'sync_version',
        description: 'åŒæ­¥ç‰ˆæœ¬å·ä¸€è‡´æ€§',
        critical: false
      },
      {
        type: 'timestamp_consistency',
        description: 'æ—¶é—´æˆ³ä¸€è‡´æ€§æ£€æŸ¥',
        critical: false
      }
    ]

    const results = await this.executeConsistencyChecks(checks)

    return {
      overallConsistency: this.calculateOverallConsistency(results),
      criticalIssues: results.filter(r => r.critical && !r.passed),
      warnings: results.filter(r => !r.critical && !r.passed),
      recommendations: this.generateRecommendations(results)
    }
  }
}
```

#### 3.2 è‡ªåŠ¨ä¿®å¤æœºåˆ¶
```typescript
// è‡ªåŠ¨ä¿®å¤ç³»ç»Ÿ
export class AutoRepairSystem {
  async repairInconsistencies(issues: ConsistencyIssue[]): Promise<RepairResult> {
    const repairs = []

    for (const issue of issues) {
      switch (issue.type) {
        case 'entity_count_mismatch':
          repairs.push(await this.repairEntityCountMismatch(issue))
          break
        case 'data_integrity_violation':
          repairs.push(await this.repairDataIntegrity(issue))
          break
        case 'sync_version_conflict':
          repairs.push(await this.repairSyncVersionConflict(issue))
          break
        case 'timestamp_inconsistency':
          repairs.push(await this.repairTimestampInconsistency(issue))
          break
      }
    }

    return {
      totalIssues: issues.length,
      repairedIssues: repairs.filter(r => r.success).length,
      failedRepairs: repairs.filter(r => !r.success).length,
      repairDetails: repairs
    }
  }
}
```

### 4. æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

#### 4.1 å®æ—¶æ€§èƒ½ç›‘æ§
```typescript
// æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
export class MigrationPerformanceMonitor {
  async monitorMigrationPerformance(): Promise<PerformanceMetrics> {
    const metrics = {
      syncLatency: await this.measureSyncLatency(),
      memoryUsage: await this.measureMemoryUsage(),
      networkThroughput: await this.measureNetworkThroughput(),
      databasePerformance: await this.measureDatabasePerformance(),
      uiResponsiveness: await this.measureUIResponsiveness()
    }

    // æ€§èƒ½é˜ˆå€¼æ£€æŸ¥
    const thresholds = {
      syncLatency: { max: 100, current: metrics.syncLatency },
      memoryUsage: { max: 500, current: metrics.memoryUsage },
      networkThroughput: { min: 1000, current: metrics.networkThroughput }
    }

    return {
      metrics,
      thresholds,
      performanceScore: this.calculatePerformanceScore(metrics, thresholds),
      recommendations: this.generatePerformanceRecommendations(metrics, thresholds)
    }
  }
}
```

#### 4.2 è‡ªé€‚åº”ä¼˜åŒ–ç­–ç•¥
```typescript
// è‡ªé€‚åº”ä¼˜åŒ–å™¨
export class AdaptiveOptimizer {
  async optimizeBasedOnMetrics(metrics: PerformanceMetrics): Promise<OptimizationAction[]> {
    const actions = []

    // åŸºäºæŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´ä¼˜åŒ–ç­–ç•¥
    if (metrics.syncLatency > 100) {
      actions.push({
        type: 'increase_batch_size',
        description: 'å¢åŠ æ‰¹é‡åŒæ­¥å¤§å°ä»¥å‡å°‘ç½‘ç»œè¯·æ±‚',
        expectedImprovement: '20%'
      })
    }

    if (metrics.memoryUsage > 500) {
      actions.push({
        type: 'enable_memory_optimization',
        description: 'å¯ç”¨å†…å­˜ä¼˜åŒ–æ¨¡å¼',
        expectedImprovement: '30%'
      })
    }

    if (metrics.networkThroughput < 1000) {
      actions.push({
        type: 'enable_compression',
        description: 'å¯ç”¨æ•°æ®å‹ç¼©',
        expectedImprovement: '40%'
      })
    }

    return actions
  }
}
```

## ğŸ—ï¸ ç»Ÿä¸€æ•°æ®æ¨¡å‹è®¾è®¡

### 1. è®¾è®¡åŸåˆ™

1. **å‘åå…¼å®¹**: æ”¯æŒç°æœ‰APIå’Œæ•°æ®æ ¼å¼
2. **ç±»å‹å®‰å…¨**: å®Œæ•´çš„TypeScriptç±»å‹å®šä¹‰
3. **æ€§èƒ½ä¼˜åŒ–**: ä¼˜åŒ–çš„ç´¢å¼•å’ŒæŸ¥è¯¢ç­–ç•¥
4. **å¯æ‰©å±•æ€§**: æ”¯æŒæœªæ¥åŠŸèƒ½æ‰©å±•
5. **ä¸€è‡´æ€§**: ç»Ÿä¸€çš„æ•°æ®æ¨¡å‹å’Œå‘½åè§„èŒƒ

### 2. ç»Ÿä¸€æ•°æ®æ¨¡å‹

#### 2.1 åŸºç¡€æ¥å£è®¾è®¡
```typescript
// åŸºç¡€åŒæ­¥æ¥å£
export interface SyncableEntity {
  id?: string
  userId?: string
  syncVersion: number
  lastSyncAt?: Date
  pendingSync: boolean
  updatedAt: Date
}

// ç»Ÿä¸€å®ä½“æšä¸¾
export enum EntityType {
  CARD = 'card',
  FOLDER = 'folder',
  TAG = 'tag',
  IMAGE = 'image',
  SETTING = 'setting',
  SESSION = 'session'
}

// ç»Ÿä¸€æ“ä½œç±»å‹
export enum OperationType {
  CREATE = 'create',
  UPDATE = 'update',
  DELETE = 'delete'
}
```

#### 2.2 æ ¸å¿ƒå®ä½“ç»Ÿä¸€
```typescript
// ç»Ÿä¸€çš„å¡ç‰‡å®ä½“
export interface UnifiedDbCard extends Omit<Card, 'id'>, SyncableEntity {
  id?: string
  // ä¼˜åŒ–å­—æ®µ
  searchVector?: string        // å…¨æ–‡æœç´¢å‘é‡
  thumbnailUrl?: string        // å¡ç‰‡ç¼©ç•¥å›¾
  fullPath?: string           // å®Œæ•´è·¯å¾„ç´¢å¼•
  // å‘åå…¼å®¹å­—æ®µ
  folderId?: string
}

// ç»Ÿä¸€çš„å›¾ç‰‡å®ä½“
export interface UnifiedDbImage {
  id?: string
  cardId: string
  userId?: string
  fileName: string
  filePath: string
  cloudUrl?: string
  thumbnailPath?: string
  metadata: ImageMetadata
  storageMode: StorageMode
  // åŒæ­¥å­—æ®µ
  syncVersion: number
  lastSyncAt?: Date
  pendingSync: boolean
  updatedAt: Date
}

// ç»Ÿä¸€çš„åŒæ­¥æ“ä½œ
export interface UnifiedSyncOperation {
  id?: string
  type: OperationType
  entity: EntityType
  entityId: string
  userId?: string
  data?: any
  timestamp: Date
  retryCount: number
  maxRetries: number
  error?: string
  priority: SyncPriority
  status: SyncStatus
}
```

### 3. æ•°æ®åº“ç‰ˆæœ¬è¿ç§»ç­–ç•¥

#### 3.1 ç‰ˆæœ¬å‡çº§è·¯å¾„
```
Version 1 (database-simple) â†’ Version 2 â†’ Version 3 (database.ts) â†’ Version 4 (unified)
```

#### 3.2 ç‰ˆæœ¬ç‰¹æ€§å¯¹æ¯”
| ç‰ˆæœ¬ | ä¸»è¦ç‰¹æ€§ | è¿ç§»å¤æ‚åº¦ | å‘åå…¼å®¹ |
|------|----------|------------|----------|
| v1.0 | åŸºç¡€åŠŸèƒ½ | - | åŸºå‡† |
| v2.0 | ç”¨æˆ·æ”¯æŒ | ä½ | å®Œå…¨ |
| v3.0 | å›¾ç‰‡ç®¡ç† | ä¸­ | å®Œå…¨ |
| v4.0 | ç»Ÿä¸€æ¶æ„ | é«˜ | å®Œå…¨ |

#### 3.3 æ•°æ®åº“å‡çº§è„šæœ¬
```typescript
class DatabaseMigrator {
  async migrateFromV1toV2(): Promise<void> {
    // æ·»åŠ ç”¨æˆ·æ”¯æŒ
    // è¿ç§»ç°æœ‰æ•°æ®ï¼Œè®¾ç½®é»˜è®¤ç”¨æˆ·
  }

  async migrateFromV2toV3(): Promise<void> {
    // æ·»åŠ å›¾ç‰‡ç®¡ç†è¡¨
    // ä¼˜åŒ–ç´¢å¼•ç»“æ„
    // è¿ç§»ç°æœ‰å›¾ç‰‡æ•°æ®
  }

  async migrateFromV3toV4(): Promise<void> {
    // é‡æ„è¡¨ç»“æ„
    // ç»Ÿä¸€æ•°æ®æ¨¡å‹
    // æ·»åŠ ç¦»çº¿æŒä¹…åŒ–åŠŸèƒ½
  }
}
```

### 4. å‘åå…¼å®¹æ€§ä¿è¯

#### 4.1 APIå…¼å®¹å±‚
```typescript
// å‘åå…¼å®¹çš„é€‚é…å™¨
export class BackwardCompatibilityAdapter {
  // æ—§ç‰ˆAPIè°ƒç”¨è½¬æ¢
  async getSettingLegacy(key: string): Promise<any> {
    return await this.unifiedDb.getSetting(key)
  }

  // æ•°æ®æ ¼å¼è½¬æ¢
  convertLegacyToUnified(legacyData: any): UnifiedData {
    // å®ç°æ•°æ®æ ¼å¼è½¬æ¢é€»è¾‘
  }

  convertUnifiedToLegacy(unifiedData: UnifiedData): any {
    // å®ç°ç»Ÿä¸€æ ¼å¼åˆ°æ—§æ ¼å¼çš„è½¬æ¢
  }
}
```

#### 4.2 æ•°æ®éªŒè¯æœºåˆ¶
```typescript
export class DataValidator {
  validateCardData(card: Partial<Card>): ValidationResult {
    // éªŒè¯å¡ç‰‡æ•°æ®å®Œæ•´æ€§
  }

  validateImageData(image: Partial<ImageData>): ValidationResult {
    // éªŒè¯å›¾ç‰‡æ•°æ®å®Œæ•´æ€§
  }

  validateConsistency(): ConsistencyReport {
    // éªŒè¯æ•´ä½“æ•°æ®ä¸€è‡´æ€§
  }
}
```

## ğŸ”„ é›¶åœæœºè¿ç§»ç­–ç•¥

### 1. è¿ç§»è®¾è®¡åŸåˆ™

1. **æœåŠ¡è¿ç»­æ€§**: è¿ç§»è¿‡ç¨‹ä¸­ä¿æŒåº”ç”¨å¯ç”¨
2. **æ•°æ®ä¸€è‡´æ€§**: ç¡®ä¿è¿ç§»å‰åæ•°æ®å®Œå…¨ä¸€è‡´
3. **å¯å›æ»šæ€§**: ä»»ä½•é˜¶æ®µéƒ½å¯ä»¥å®‰å…¨å›æ»š
4. **æ¸è¿›å¼è¿ç§»**: åˆ†é˜¶æ®µé™ä½é£é™©
5. **å®æ—¶ç›‘æ§**: å…¨ç¨‹ç›‘æ§è¿ç§»çŠ¶æ€

### 2. è¿ç§»æ‰§è¡Œæµç¨‹

#### 2.1 è¿ç§»å‰å‡†å¤‡é˜¶æ®µ
```typescript
export class MigrationPreparation {
  async prepareMigration(): Promise<MigrationContext> {
    const context: MigrationContext = {
      timestamp: new Date(),
      sourceVersion: await this.detectCurrentVersion(),
      targetVersion: '4.0.0',
      backup: null,
      validation: null,
      rollbackPoint: null
    }

    // 1. æ£€æµ‹å½“å‰æ•°æ®åº“ç‰ˆæœ¬
    // 2. åˆ›å»ºå®Œæ•´å¤‡ä»½
    // 3. éªŒè¯æ•°æ®å®Œæ•´æ€§
    // 4. è®¾ç½®å›æ»šç‚¹
    // 5. é¢„ä¼°è¿ç§»æ—¶é—´å’Œèµ„æºéœ€æ±‚

    return context
  }

  async createBackup(): Promise<DatabaseBackup> {
    // åˆ›å»ºå®Œæ•´æ•°æ®åº“å¤‡ä»½
    // åŒ…æ‹¬æ‰€æœ‰è¡¨å’Œç´¢å¼•
    // è®¡ç®—æ•°æ®å“ˆå¸Œç”¨äºéªŒè¯
  }

  async validateDataIntegrity(): Promise<DataValidation> {
    // éªŒè¯æ‰€æœ‰æ•°æ®çš„å®Œæ•´æ€§
    // æ£€æŸ¥å¤–é”®çº¦æŸ
    // æ£€æŸ¥æ•°æ®æ ¼å¼ä¸€è‡´æ€§
  }
}
```

#### 2.2 æ•°æ®è¿ç§»é˜¶æ®µ
```typescript
export class DataMigration {
  async executeMigration(context: MigrationContext): Promise<MigrationResult> {
    try {
      // é˜¶æ®µ1: å…ƒæ•°æ®è¿ç§»
      await this.migrateMetadata(context)

      // é˜¶æ®µ2: æ ¸å¿ƒæ•°æ®è¿ç§»
      await this.migrateCoreData(context)

      // é˜¶æ®µ3: å…³è”æ•°æ®è¿ç§»
      await this.migrateRelatedData(context)

      // é˜¶æ®µ4: ç´¢å¼•é‡å»º
      await this.rebuildIndexes(context)

      // é˜¶æ®µ5: æ•°æ®éªŒè¯
      await this.validateMigration(context)

      return {
        success: true,
        timestamp: new Date(),
        recordsMigrated: context.recordsMigrated,
        duration: context.duration
      }
    } catch (error) {
      // è‡ªåŠ¨è§¦å‘å›æ»š
      await this.rollbackMigration(context, error)
      throw error
    }
  }

  private async migrateMetadata(context: MigrationContext): Promise<void> {
    // è¿ç§»ç”¨æˆ·è®¾ç½®ã€é…ç½®ç­‰å…ƒæ•°æ®
    // è¿™äº›æ•°æ®é€šå¸¸ä½“ç§¯å°ï¼Œä½†å¾ˆé‡è¦
  }

  private async migrateCoreData(context: MigrationContext): Promise<void> {
    // åˆ†æ‰¹è¿ç§»æ ¸å¿ƒä¸šåŠ¡æ•°æ®
    // å®ç°åˆ†é¡µå¤„ç†ï¼Œé¿å…å†…å­˜é—®é¢˜
  }

  private async migrateRelatedData(context: MigrationContext): Promise<void> {
    // è¿ç§»å…³è”æ•°æ®ï¼Œå¦‚å›¾ç‰‡ã€é™„ä»¶ç­‰
    // è¿™äº›æ•°æ®å¯èƒ½ä½“ç§¯è¾ƒå¤§ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
  }
}
```

#### 2.3 è¿ç§»åéªŒè¯é˜¶æ®µ
```typescript
export class MigrationVerification {
  async verifyMigration(context: MigrationContext): Promise<VerificationResult> {
    const result: VerificationResult = {
      timestamp: new Date(),
      dataIntegrity: false,
      performanceMetrics: null,
      userImpact: null
    }

    // 1. æ•°æ®å®Œæ•´æ€§éªŒè¯
    result.dataIntegrity = await this.verifyDataIntegrity(context)

    // 2. æ€§èƒ½åŸºå‡†æµ‹è¯•
    result.performanceMetrics = await this.benchmarkPerformance()

    // 3. ç”¨æˆ·ä½“éªŒè¯„ä¼°
    result.userImpact = await this.assessUserImpact()

    return result
  }

  private async verifyDataIntegrity(context: MigrationContext): Promise<boolean> {
    // å¯¹æ¯”è¿ç§»å‰åçš„æ•°æ®
    // éªŒè¯è®°å½•æ•°é‡ä¸€è‡´æ€§
    // éªŒè¯æ•°æ®å†…å®¹å®Œæ•´æ€§
    // éªŒè¯å…³è”å…³ç³»æ­£ç¡®æ€§
  }
}
```

### 3. æ•°æ®åˆ†æ‰¹å¤„ç†ç­–ç•¥

#### 3.1 æ‰¹å¤„ç†é…ç½®
```typescript
export interface BatchConfig {
  batchSize: number                    // æ¯æ‰¹å¤„ç†çš„è®°å½•æ•°
  maxConcurrentBatches: number        // æœ€å¤§å¹¶å‘æ‰¹æ¬¡æ•°
  retryAttempts: number              // é‡è¯•æ¬¡æ•°
  retryDelay: number                 // é‡è¯•å»¶è¿Ÿ(ms)
  timeout: number                    // æ‰¹å¤„ç†è¶…æ—¶(ms)
  progressInterval: number           // è¿›åº¦æŠ¥å‘Šé—´éš”(ms)
}

export const MIGRATION_BATCH_CONFIG: BatchConfig = {
  batchSize: 1000,                  // æ¯æ‰¹1000æ¡è®°å½•
  maxConcurrentBatches: 3,          // æœ€å¤š3ä¸ªå¹¶å‘æ‰¹æ¬¡
  retryAttempts: 3,                  // æœ€å¤šé‡è¯•3æ¬¡
  retryDelay: 1000,                 // é‡è¯•é—´éš”1ç§’
  timeout: 30000,                   // æ‰¹å¤„ç†è¶…æ—¶30ç§’
  progressInterval: 2000            // æ¯2ç§’æŠ¥å‘Šè¿›åº¦
}
```

#### 3.2 æ‰¹å¤„ç†æ‰§è¡Œå™¨
```typescript
export class BatchMigrationExecutor {
  async executeBatches<T>(
    items: T[],
    processor: (batch: T[]) => Promise<BatchResult>,
    config: BatchConfig = MIGRATION_BATCH_CONFIG
  ): Promise<MigrationProgress> {
    const progress: MigrationProgress = {
      totalItems: items.length,
      processedItems: 0,
      failedItems: 0,
      startTime: new Date(),
      batches: []
    }

    // åˆ›å»ºæ‰¹æ¬¡
    const batches = this.createBatches(items, config.batchSize)

    // å¹¶å‘æ‰§è¡Œæ‰¹æ¬¡
    const semaphore = new Semaphore(config.maxConcurrentBatches)
    const batchPromises = batches.map(async (batch) => {
      await semaphore.acquire()
      try {
        const result = await this.executeBatchWithRetry(batch, processor, config)
        progress.batches.push(result)
        progress.processedItems += result.processedCount
        progress.failedItems += result.failedCount
        return result
      } finally {
        semaphore.release()
      }
    })

    await Promise.all(batchPromises)
    progress.endTime = new Date()

    return progress
  }

  private async executeBatchWithRetry<T>(
    batch: T[],
    processor: (batch: T[]) => Promise<BatchResult>,
    config: BatchConfig
  ): Promise<BatchResult> {
    let attempts = 0
    let lastError: Error | null = null

    while (attempts < config.retryAttempts) {
      try {
        const result = await Promise.race([
          processor(batch),
          new Promise<never>((_, reject) =>
            setTimeout(() => reject(new Error('Batch timeout')), config.timeout)
          )
        ])
        return result
      } catch (error) {
        lastError = error as Error
        attempts++
        if (attempts < config.retryAttempts) {
          await new Promise(resolve => setTimeout(resolve, config.retryDelay))
        }
      }
    }

    throw lastError || new Error('Batch processing failed')
  }
}
```

### 4. äº‹åŠ¡æ€§è¿ç§»æœºåˆ¶

#### 4.1 äº‹åŠ¡ç®¡ç†å™¨
```typescript
export class TransactionalMigration {
  async executeInTransaction<T>(
    operations: () => Promise<T>,
    context: MigrationContext
  ): Promise<T> {
    const transactionId = crypto.randomUUID()

    try {
      context.currentTransaction = {
        id: transactionId,
        startTime: new Date(),
        operations: []
      }

      // å¼€å§‹äº‹åŠ¡
      await this.beginTransaction(transactionId)

      // æ‰§è¡Œæ“ä½œ
      const result = await operations()

      // æäº¤äº‹åŠ¡
      await this.commitTransaction(transactionId)

      context.currentTransaction.endTime = new Date()
      context.currentTransaction.status = 'completed'

      return result
    } catch (error) {
      // å›æ»šäº‹åŠ¡
      await this.rollbackTransaction(transactionId)

      context.currentTransaction.endTime = new Date()
      context.currentTransaction.status = 'failed'
      context.currentTransaction.error = error as Error

      throw error
    }
  }

  private async beginTransaction(transactionId: string): Promise<void> {
    // å®ç°äº‹åŠ¡å¼€å§‹é€»è¾‘
    // å¯ä»¥ä½¿ç”¨IndexedDBäº‹åŠ¡æˆ–æ¨¡æ‹Ÿäº‹åŠ¡
  }

  private async commitTransaction(transactionId: string): Promise<void> {
    // å®ç°äº‹åŠ¡æäº¤é€»è¾‘
  }

  private async rollbackTransaction(transactionId: string): Promise<void> {
    // å®ç°äº‹åŠ¡å›æ»šé€»è¾‘
    // æ¢å¤äº‹åŠ¡å¼€å§‹å‰çš„çŠ¶æ€
  }
}
```

#### 4.2 æ£€æŸ¥ç‚¹å’Œæ¢å¤æœºåˆ¶
```typescript
export class CheckpointManager {
  async createCheckpoint(context: MigrationContext): Promise<Checkpoint> {
    const checkpoint: Checkpoint = {
      id: crypto.randomUUID(),
      timestamp: new Date(),
      migrationId: context.id,
      progress: context.getProgress(),
      state: await this.captureState(),
      checksum: await this.calculateChecksum()
    }

    // ä¿å­˜æ£€æŸ¥ç‚¹
    await this.saveCheckpoint(checkpoint)

    return checkpoint
  }

  async restoreFromCheckpoint(checkpointId: string): Promise<void> {
    const checkpoint = await this.loadCheckpoint(checkpointId)

    // éªŒè¯æ£€æŸ¥ç‚¹å®Œæ•´æ€§
    if (!await this.verifyCheckpoint(checkpoint)) {
      throw new Error('Checkpoint verification failed')
    }

    // æ¢å¤çŠ¶æ€
    await this.restoreState(checkpoint.state)

    // æ›´æ–°è¿ç§»ä¸Šä¸‹æ–‡
    context.restoreFromCheckpoint(checkpoint)
  }

  async cleanupOldCheckpoints(retentionDays: number = 7): Promise<void> {
    const cutoffDate = new Date()
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays)

    await this.deleteCheckpointsBefore(cutoffDate)
  }
}
```

## ğŸ›¡ï¸ æ•°æ®å®‰å…¨ä¿è¯ç­–ç•¥

### 1. æ•°æ®å¤‡ä»½å’Œæ¢å¤æœºåˆ¶

#### 1.1 å¤šå±‚å¤‡ä»½ç­–ç•¥
```typescript
export interface BackupStrategy {
  fullBackup: BackupConfig           // å®Œæ•´å¤‡ä»½é…ç½®
  incrementalBackup: BackupConfig    // å¢é‡å¤‡ä»½é…ç½®
  preMigrationBackup: BackupConfig   // è¿ç§»å‰å¤‡ä»½é…ç½®
  rollbackBackup: BackupConfig       // å›æ»šå¤‡ä»½é…ç½®
}

export interface BackupConfig {
  enabled: boolean
  compression: boolean
  encryption: boolean
  retention: number                 // ä¿ç•™å¤©æ•°
  schedule: BackupSchedule
  storage: BackupStorage
}

export const DEFAULT_BACKUP_STRATEGY: BackupStrategy = {
  fullBackup: {
    enabled: true,
    compression: true,
    encryption: true,
    retention: 30,
    schedule: { type: 'daily', time: '02:00' },
    storage: { type: 'local', path: './backups' }
  },
  incrementalBackup: {
    enabled: true,
    compression: true,
    encryption: true,
    retention: 7,
    schedule: { type: 'hourly', interval: 4 },
    storage: { type: 'local', path: './backups/incremental' }
  },
  preMigrationBackup: {
    enabled: true,
    compression: true,
    encryption: true,
    retention: 90,
    schedule: { type: 'manual' },
    storage: { type: 'multiple', locations: ['local', 'cloud'] }
  },
  rollbackBackup: {
    enabled: true,
    compression: true,
    encryption: true,
    retention: 30,
    schedule: { type: 'auto', trigger: 'migration' },
    storage: { type: 'local', path: './backups/rollback' }
  }
}
```

#### 1.2 å¤‡ä»½æ‰§è¡Œå™¨
```typescript
export class BackupExecutor {
  async createFullBackup(): Promise<BackupResult> {
    const backupId = crypto.randomUUID()
    const startTime = new Date()

    try {
      // 1. è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
      const stats = await this.getDatabaseStats()

      // 2. åˆ›å»ºä¸´æ—¶ç›®å½•
      const tempDir = await this.createTempDirectory()

      // 3. å¯¼å‡ºæ•°æ®
      const data = await this.exportAllData()

      // 4. å‹ç¼©æ•°æ®
      const compressedData = await this.compressData(data)

      // 5. åŠ å¯†æ•°æ®
      const encryptedData = await this.encryptData(compressedData)

      // 6. è®¡ç®—æ ¡éªŒå’Œ
      const checksum = await this.calculateChecksum(encryptedData)

      // 7. ä¿å­˜å¤‡ä»½
      const backupPath = await this.saveBackup(backupId, encryptedData)

      // 8. è®°å½•å…ƒæ•°æ®
      const metadata: BackupMetadata = {
        id: backupId,
        type: 'full',
        timestamp: startTime,
        size: encryptedData.byteLength,
        checksum,
        stats,
        path: backupPath
      }

      await this.saveBackupMetadata(metadata)

      return {
        success: true,
        backupId,
        metadata,
        duration: Date.now() - startTime.getTime()
      }
    } catch (error) {
      await this.cleanupTempFiles(tempDir)
      throw error
    }
  }

  async restoreFromBackup(backupId: string): Promise<RestoreResult> {
    const startTime = new Date()

    try {
      // 1. åŠ è½½å¤‡ä»½å…ƒæ•°æ®
      const metadata = await this.loadBackupMetadata(backupId)

      // 2. éªŒè¯å¤‡ä»½å®Œæ•´æ€§
      if (!await this.verifyBackupIntegrity(metadata)) {
        throw new Error('Backup integrity verification failed')
      }

      // 3. åˆ›å»ºå½“å‰çŠ¶æ€å¤‡ä»½ï¼ˆå›æ»šç‚¹ï¼‰
      await this.createRollbackPoint()

      // 4. è§£å¯†æ•°æ®
      const encryptedData = await this.loadBackupData(metadata.path)
      const decryptedData = await this.decryptData(encryptedData)

      // 5. è§£å‹æ•°æ®
      const data = await this.decompressData(decryptedData)

      // 6. å¯¼å…¥æ•°æ®
      await this.importAllData(data)

      // 7. éªŒè¯æ¢å¤ç»“æœ
      const validationResult = await this.validateRestoredData(metadata)

      return {
        success: true,
        backupId,
        metadata,
        validation: validationResult,
        duration: Date.now() - startTime.getTime()
      }
    } catch (error) {
      // æ¢å¤å¤±è´¥æ—¶è‡ªåŠ¨å›æ»š
      await this.rollbackToLastPoint()
      throw error
    }
  }
}
```

### 2. æ•°æ®åŠ å¯†å’Œä¿æŠ¤

#### 2.1 åŠ å¯†ç­–ç•¥
```typescript
export class DataEncryption {
  private readonly encryptionKey: CryptoKey

  constructor(private readonly keyStorage: KeyStorage) {
    this.encryptionKey = keyStorage.getOrCreateKey()
  }

  async encryptData(data: Uint8Array): Promise<Uint8Array> {
    const iv = crypto.getRandomValues(new Uint8Array(12))
    const algorithm = { name: 'AES-GCM', iv }

    const encryptedData = await crypto.subtle.encrypt(
      algorithm,
      this.encryptionKey,
      data
    )

    // ç»„åˆ IV + åŠ å¯†æ•°æ®
    const result = new Uint8Array(iv.length + encryptedData.byteLength)
    result.set(iv)
    result.set(new Uint8Array(encryptedData), iv.length)

    return result
  }

  async decryptData(encryptedData: Uint8Array): Promise<Uint8Array> {
    const iv = encryptedData.slice(0, 12)
    const data = encryptedData.slice(12)

    const algorithm = { name: 'AES-GCM', iv }

    const decryptedData = await crypto.subtle.decrypt(
      algorithm,
      this.encryptionKey,
      data
    )

    return new Uint8Array(decryptedData)
  }

  async hashData(data: Uint8Array): Promise<string> {
    const hashBuffer = await crypto.subtle.digest('SHA-256', data)
    const hashArray = Array.from(new Uint8Array(hashBuffer))
    return hashArray.map(b => b.toString(16).padStart(2, '0')).join('')
  }
}
```

#### 2.2 å¯†é’¥ç®¡ç†
```typescript
export class KeyStorage {
  async getOrCreateKey(): Promise<CryptoKey> {
    try {
      // å°è¯•ä»å®‰å…¨å­˜å‚¨è·å–ç°æœ‰å¯†é’¥
      const existingKey = await this.loadKey()
      if (existingKey) {
        return existingKey
      }
    } catch (error) {
      console.warn('Failed to load existing key, creating new one')
    }

    // ç”Ÿæˆæ–°å¯†é’¥
    return await this.generateAndStoreKey()
  }

  private async generateAndStoreKey(): Promise<CryptoKey> {
    const key = await crypto.subtle.generateKey(
      {
        name: 'AES-GCM',
        length: 256
      },
      true,
      ['encrypt', 'decrypt']
    )

    // å¯¼å‡ºå¹¶å­˜å‚¨å¯†é’¥ï¼ˆå®é™…å®ç°åº”è¯¥ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼ï¼‰
    const exportedKey = await crypto.subtle.exportKey('raw', key)
    await this.storeKey(exportedKey)

    return key
  }

  private async storeKey(keyData: ArrayBuffer): Promise<void> {
    // åœ¨å®é™…å®ç°ä¸­ï¼Œåº”è¯¥ä½¿ç”¨æµè§ˆå™¨æä¾›çš„æ›´å®‰å…¨çš„å­˜å‚¨æ–¹å¼
    // ä¾‹å¦‚ï¼šCredential Management API æˆ– Secure Storage
    const encryptedKeyData = await this.encryptForStorage(keyData)
    localStorage.setItem('encryption_key', JSON.stringify({
      data: Array.from(new Uint8Array(encryptedKeyData)),
      salt: Array.from(this.generateSalt())
    }))
  }

  private async loadKey(): Promise<CryptoKey | null> {
    try {
      const stored = localStorage.getItem('encryption_key')
      if (!stored) return null

      const { data, salt } = JSON.parse(stored)
      const keyData = await this.decryptFromStorage(
        new Uint8Array(data),
        new Uint8Array(salt)
      )

      return await crypto.subtle.importKey(
        'raw',
        keyData,
        { name: 'AES-GCM' },
        true,
        ['encrypt', 'decrypt']
      )
    } catch (error) {
      console.error('Failed to load encryption key:', error)
      return null
    }
  }
}
```

### 3. æ•°æ®ä¸€è‡´æ€§éªŒè¯

#### 3.1 å®Œæ•´æ€§æ£€æŸ¥å™¨
```typescript
export class DataConsistencyChecker {
  async checkDataConsistency(): Promise<ConsistencyReport> {
    const report: ConsistencyReport = {
      timestamp: new Date(),
      totalRecords: 0,
      inconsistencies: [],
      warnings: [],
      isValid: true
    }

    // æ£€æŸ¥æ‰€æœ‰è¡¨çš„è®°å½•æ•°ä¸€è‡´æ€§
    await this.checkRecordCounts(report)

    // æ£€æŸ¥å¤–é”®çº¦æŸ
    await this.checkForeignKeys(report)

    // æ£€æŸ¥æ•°æ®æ ¼å¼ä¸€è‡´æ€§
    await this.checkDataFormats(report)

    // æ£€æŸ¥ç´¢å¼•ä¸€è‡´æ€§
    await this.checkIndexConsistency(report)

    // æ£€æŸ¥åŒæ­¥çŠ¶æ€ä¸€è‡´æ€§
    await this.checkSyncConsistency(report)

    report.isValid = report.inconsistencies.length === 0

    return report
  }

  private async checkRecordCounts(report: ConsistencyReport): Promise<void> {
    const [cardCount, folderCount, tagCount, imageCount] = await Promise.all([
      db.cards.count(),
      db.folders.count(),
      db.tags.count(),
      db.images.count()
    ])

    report.totalRecords = cardCount + folderCount + tagCount + imageCount

    // æ£€æŸ¥æ˜¯å¦æœ‰æ„å¤–çš„é›¶è®°å½•æ•°
    if (cardCount === 0 && (folderCount > 0 || tagCount > 0)) {
      report.inconsistencies.push({
        type: 'record_count',
        severity: 'high',
        message: 'Cards table is empty but other tables have data',
        details: { cardCount, folderCount, tagCount }
      })
    }
  }

  private async checkForeignKeys(report: ConsistencyReport): Promise<void> {
    // æ£€æŸ¥å¡ç‰‡çš„folderIdæ˜¯å¦æœ‰æ•ˆ
    const invalidFolderCards = await db.cards
      .filter(card => card.folderId && !this.isValidFolderId(card.folderId))
      .count()

    if (invalidFolderCards > 0) {
      report.inconsistencies.push({
        type: 'foreign_key',
        severity: 'medium',
        message: `Found ${invalidFolderCards} cards with invalid folder references`,
        details: { invalidCount: invalidFolderCards }
      })
    }

    // æ£€æŸ¥å›¾ç‰‡çš„cardIdæ˜¯å¦æœ‰æ•ˆ
    const orphanedImages = await db.images
      .filter(image => !this.isValidCardId(image.cardId))
      .count()

    if (orphanedImages > 0) {
      report.warnings.push({
        type: 'orphaned_data',
        severity: 'low',
        message: `Found ${orphanedImages} orphaned images`,
        details: { orphanedCount: orphanedImages }
      })
    }
  }

  private async checkSyncConsistency(report: ConsistencyReport): Promise<void> {
    // æ£€æŸ¥syncVersionçš„ä¸€è‡´æ€§
    const inconsistentSyncVersions = await this.findInconsistentSyncVersions()

    if (inconsistentSyncVersions.length > 0) {
      report.inconsistencies.push({
        type: 'sync_consistency',
        severity: 'high',
        message: 'Found inconsistent sync versions',
        details: { entities: inconsistentSyncVersions }
      })
    }
  }
}
```

### 4. åº”æ€¥å“åº”é¢„æ¡ˆ

#### 4.1 åº”æ€¥å“åº”æµç¨‹
```typescript
export class EmergencyResponse {
  private alertSystem: AlertSystem
  private rollbackManager: RollbackManager
  private notificationService: NotificationService

  async handleMigrationFailure(error: Error, context: MigrationContext): Promise<void> {
    const severity = this.assessSeverity(error, context)

    // 1. ç«‹å³æš‚åœè¿ç§»
    await this.pauseMigration()

    // 2. å‘é€å‘Šè­¦
    await this.alertSystem.sendAlert({
      type: 'migration_failure',
      severity,
      message: error.message,
      context: this.sanitizeContext(context),
      timestamp: new Date()
    })

    // 3. å¯åŠ¨è¯Šæ–­
    const diagnosis = await this.diagnoseFailure(error, context)

    // 4. æ ¹æ®ä¸¥é‡ç¨‹åº¦é‡‡å–è¡ŒåŠ¨
    switch (severity) {
      case 'critical':
        await this.handleCriticalFailure(error, context, diagnosis)
        break
      case 'high':
        await this.handleHighSeverityFailure(error, context, diagnosis)
        break
      case 'medium':
        await this.handleMediumSeverityFailure(error, context, diagnosis)
        break
      case 'low':
        await this.handleLowSeverityFailure(error, context, diagnosis)
        break
    }

    // 5. é€šçŸ¥ç›¸å…³äººå‘˜
    await this.notificationService.notifyStakeholders({
      event: 'migration_failure',
      severity,
      details: diagnosis,
      estimatedResolution: this.estimateResolutionTime(severity)
    })
  }

  private async handleCriticalFailure(error: Error, context: MigrationContext, diagnosis: Diagnosis): Promise<void> {
    console.error('CRITICAL MIGRATION FAILURE:', error)

    // 1. ç«‹å³å›æ»šåˆ°æœ€åå·²çŸ¥çš„è‰¯å¥½çŠ¶æ€
    await this.rollbackManager.emergencyRollback(context)

    // 2. éªŒè¯å›æ»šç»“æœ
    const rollbackValidation = await this.validateRollbackResult()

    if (!rollbackValidation.success) {
      // å¦‚æœå›æ»šå¤±è´¥ï¼Œå¯åŠ¨ç´§æ€¥æ¢å¤æµç¨‹
      await this.emergencyRecovery()
    }

    // 3. ç”Ÿæˆè¯¦ç»†é”™è¯¯æŠ¥å‘Š
    await this.generateFailureReport(error, context, diagnosis)

    // 4. å¯åŠ¨è°ƒæŸ¥ç¨‹åº
    await this.initiateInvestigation()
  }

  private async emergencyRecovery(): Promise<void> {
    console.warn('Starting emergency recovery procedure...')

    // 1. å°è¯•ä»æœ€æ–°çš„å¯ç”¨å¤‡ä»½æ¢å¤
    const latestBackup = await this.findLatestValidBackup()

    if (latestBackup) {
      try {
        await this.restoreFromBackup(latestBackup.id)
        console.log('Emergency recovery successful from backup:', latestBackup.id)
        return
      } catch (error) {
        console.error('Emergency recovery from backup failed:', error)
      }
    }

    // 2. å¦‚æœå¤‡ä»½æ¢å¤å¤±è´¥ï¼Œå°è¯•æ•°æ®é‡å»º
    await this.attemptDataReconstruction()
  }
}
```

#### 4.2 ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ
```typescript
export class MigrationMonitoring {
  private metrics: MigrationMetrics
  private thresholds: MonitoringThresholds

  constructor() {
    this.metrics = new MigrationMetrics()
    this.thresholds = {
      duration: { warning: 3600000, critical: 7200000 }, // 1å°æ—¶è­¦å‘Šï¼Œ2å°æ—¶ä¸¥é‡
      failureRate: { warning: 0.05, critical: 0.1 },    // 5%è­¦å‘Šï¼Œ10%ä¸¥é‡
      memoryUsage: { warning: 0.7, critical: 0.9 },     // 70%è­¦å‘Šï¼Œ90%ä¸¥é‡
      dataSize: { warning: 1024 * 1024 * 1024, critical: 2 * 1024 * 1024 * 1024 } // 1GBè­¦å‘Šï¼Œ2GBä¸¥é‡
    }
  }

  async checkMigrationHealth(context: MigrationContext): Promise<HealthReport> {
    const report: HealthReport = {
      timestamp: new Date(),
      overall: 'healthy',
      checks: []
    }

    // æ£€æŸ¥è¿ç§»æŒç»­æ—¶é—´
    const duration = Date.now() - context.startTime.getTime()
    this.checkDuration(duration, report)

    // æ£€æŸ¥å¤±è´¥ç‡
    const failureRate = this.calculateFailureRate(context)
    this.checkFailureRate(failureRate, report)

    // æ£€æŸ¥å†…å­˜ä½¿ç”¨
    const memoryUsage = await this.getMemoryUsage()
    this.checkMemoryUsage(memoryUsage, report)

    // æ£€æŸ¥æ•°æ®å¤§å°
    const dataSize = await this.estimateDataSize(context)
    this.checkDataSize(dataSize, report)

    // ç¡®å®šæ•´ä½“å¥åº·çŠ¶æ€
    report.overall = this.determineOverallHealth(report.checks)

    return report
  }

  private checkDuration(duration: number, report: HealthReport): void {
    const check: HealthCheck = {
      type: 'duration',
      value: duration,
      status: 'healthy'
    }

    if (duration > this.thresholds.duration.critical) {
      check.status = 'critical'
      check.message = `Migration duration (${this.formatDuration(duration)}) exceeds critical threshold`
    } else if (duration > this.thresholds.duration.warning) {
      check.status = 'warning'
      check.message = `Migration duration (${this.formatDuration(duration)}) exceeds warning threshold`
    }

    report.checks.push(check)
  }

  private determineOverallHealth(checks: HealthCheck[]): 'healthy' | 'warning' | 'critical' {
    const hasCritical = checks.some(c => c.status === 'critical')
    const hasWarning = checks.some(c => c.status === 'warning')

    if (hasCritical) return 'critical'
    if (hasWarning) return 'warning'
    return 'healthy'
  }
}
```

## ğŸ“Š ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶

### 1. å®æ—¶ç›‘æ§ä»ªè¡¨æ¿

#### 1.1 ç›‘æ§æŒ‡æ ‡å®šä¹‰
```typescript
export interface MigrationMetrics {
  // åŸºç¡€æŒ‡æ ‡
  startTime: Date
  duration: number
  progress: number

  // æ•°æ®æŒ‡æ ‡
  totalRecords: number
  processedRecords: number
  failedRecords: number
  successRate: number

  // æ€§èƒ½æŒ‡æ ‡
  averageProcessingTime: number
  memoryUsage: number
  cpuUsage: number
  networkLatency: number

  // é”™è¯¯æŒ‡æ ‡
  errorCount: number
  errorRate: number
  retryCount: number

  // çŠ¶æ€æŒ‡æ ‡
  currentPhase: string
  activeBatches: number
  queueSize: number
}

export interface MetricThreshold {
  warning: number
  critical: number
  recovery?: number
}

export const MIGRATION_THRESHOLDS = {
  duration: { warning: 3600000, critical: 7200000 },       // 1å°æ—¶è­¦å‘Šï¼Œ2å°æ—¶ä¸¥é‡
  failureRate: { warning: 0.05, critical: 0.1 },           // 5%è­¦å‘Šï¼Œ10%ä¸¥é‡
  memoryUsage: { warning: 0.7, critical: 0.9 },            // 70%è­¦å‘Šï¼Œ90%ä¸¥é‡
  cpuUsage: { warning: 0.8, critical: 0.95 },              // 80%è­¦å‘Šï¼Œ95%ä¸¥é‡
  networkLatency: { warning: 1000, critical: 5000 },        // 1ç§’è­¦å‘Šï¼Œ5ç§’ä¸¥é‡
  batchSize: { warning: 2000, critical: 5000 },             // 2Kè­¦å‘Šï¼Œ5Kä¸¥é‡
  activeBatches: { warning: 5, critical: 10 }              // 5ä¸ªè­¦å‘Šï¼Œ10ä¸ªä¸¥é‡
}
```

#### 1.2 å®æ—¶ç›‘æ§æœåŠ¡
```typescript
export class MigrationMonitor {
  private metrics: MigrationMetrics
  private thresholds: MetricThresholds
  private subscribers: Map<string, MetricSubscriber> = new Map()
  private intervalId?: NodeJS.Timeout

  constructor(thresholds: MetricThresholds = MIGRATION_THRESHOLDS) {
    this.metrics = this.initializeMetrics()
    this.thresholds = thresholds
  }

  startMonitoring(intervalMs: number = 5000): void {
    this.intervalId = setInterval(async () => {
      await this.collectMetrics()
      await this.evaluateThresholds()
      await this.notifySubscribers()
    }, intervalMs)

    console.log('Migration monitoring started with', intervalMs, 'ms interval')
  }

  stopMonitoring(): void {
    if (this.intervalId) {
      clearInterval(this.intervalId)
      this.intervalId = undefined
      console.log('Migration monitoring stopped')
    }
  }

  private async collectMetrics(): Promise<void> {
    // æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
    const [memoryUsage, cpuUsage, networkLatency] = await Promise.all([
      this.getMemoryUsage(),
      this.getCpuUsage(),
      this.getNetworkLatency()
    ])

    // æ›´æ–°æŒ‡æ ‡
    this.metrics.duration = Date.now() - this.metrics.startTime.getTime()
    this.metrics.memoryUsage = memoryUsage
    this.metrics.cpuUsage = cpuUsage
    this.metrics.networkLatency = networkLatency
    this.metrics.successRate = this.calculateSuccessRate()
  }

  private async evaluateThresholds(): Promise<void> {
    const alerts: Alert[] = []

    // è¯„ä¼°å„é¡¹æŒ‡æ ‡
    this.evaluateMetric('duration', this.metrics.duration, alerts)
    this.evaluateMetric('memoryUsage', this.metrics.memoryUsage, alerts)
    this.evaluateMetric('cpuUsage', this.metrics.cpuUsage, alerts)
    this.evaluateMetric('failureRate', this.metrics.errorRate, alerts)

    // å¦‚æœæœ‰å‘Šè­¦ï¼Œé€šçŸ¥è®¢é˜…è€…
    if (alerts.length > 0) {
      await this.publishAlerts(alerts)
    }
  }

  subscribe(subscriber: MetricSubscriber): string {
    const id = crypto.randomUUID()
    this.subscribers.set(id, subscriber)
    return id
  }

  unsubscribe(id: string): void {
    this.subscribers.delete(id)
  }
}
```

### 2. å‘Šè­¦è§„åˆ™å¼•æ“

#### 2.1 å‘Šè­¦è§„åˆ™å®šä¹‰
```typescript
export interface AlertRule {
  id: string
  name: string
  description: string
  condition: (metrics: MigrationMetrics) => boolean
  severity: 'info' | 'warning' | 'critical'
  actions: AlertAction[]
  cooldownPeriod: number  // å†·å´æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
  enabled: boolean
}

export interface AlertAction {
  type: 'log' | 'notify' | 'pause' | 'rollback' | 'scale'
  config: any
}

export const DEFAULT_ALERT_RULES: AlertRule[] = [
  {
    id: 'high_failure_rate',
    name: 'High Failure Rate',
    description: 'Migration failure rate exceeds threshold',
    condition: (metrics) => metrics.errorRate > 0.1,
    severity: 'critical',
    cooldownPeriod: 300000, // 5åˆ†é’Ÿå†·å´
    actions: [
      { type: 'log', config: { level: 'error' } },
      { type: 'notify', config: { channels: ['email', 'slack'] } },
      { type: 'pause', config: { reason: 'high_failure_rate' } }
    ],
    enabled: true
  },
  {
    id: 'memory_exhaustion',
    name: 'Memory Exhaustion',
    description: 'Memory usage exceeds critical threshold',
    condition: (metrics) => metrics.memoryUsage > 0.9,
    severity: 'critical',
    cooldownPeriod: 600000, // 10åˆ†é’Ÿå†·å´
    actions: [
      { type: 'log', config: { level: 'error' } },
      { type: 'notify', config: { channels: ['email', 'sms'] } },
      { type: 'scale', config: { action: 'reduce_batch_size' } }
    ],
    enabled: true
  },
  {
    id: 'duration_warning',
    name: 'Long Running Migration',
    description: 'Migration is taking longer than expected',
    condition: (metrics) => metrics.duration > 3600000, // 1å°æ—¶
    severity: 'warning',
    cooldownPeriod: 1800000, // 30åˆ†é’Ÿå†·å´
    actions: [
      { type: 'log', config: { level: 'warn' } },
      { type: 'notify', config: { channels: ['email'] } }
    ],
    enabled: true
  }
]
```

#### 2.2 å‘Šè­¦å¤„ç†å™¨
```typescript
export class AlertProcessor {
  private rules: AlertRule[]
  private activeAlerts: Map<string, ActiveAlert> = new Map()
  private lastTriggered: Map<string, number> = new Map()

  constructor(rules: AlertRule[] = DEFAULT_ALERT_RULES) {
    this.rules = rules
  }

  async processMetrics(metrics: MigrationMetrics): Promise<Alert[]> {
    const triggeredAlerts: Alert[] = []
    const now = Date.now()

    for (const rule of this.rules) {
      if (!rule.enabled) continue

      // æ£€æŸ¥å†·å´æœŸ
      const lastTriggered = this.lastTriggered.get(rule.id) || 0
      if (now - lastTriggered < rule.cooldownPeriod) {
        continue
      }

      // æ£€æŸ¥æ¡ä»¶
      if (rule.condition(metrics)) {
        const alert = this.createAlert(rule, metrics)
        triggeredAlerts.push(alert)

        // æ‰§è¡Œå‘Šè­¦åŠ¨ä½œ
        await this.executeActions(alert, rule.actions)

        // æ›´æ–°è§¦å‘æ—¶é—´
        this.lastTriggered.set(rule.id, now)

        // æ¿€æ´»å‘Šè­¦
        this.activateAlert(alert)
      }
    }

    return triggeredAlerts
  }

  private createAlert(rule: AlertRule, metrics: MigrationMetrics): Alert {
    return {
      id: crypto.randomUUID(),
      ruleId: rule.id,
      name: rule.name,
      description: rule.description,
      severity: rule.severity,
      timestamp: new Date(),
      metrics: { ...metrics },
      metadata: {
        environment: process.env.NODE_ENV || 'development',
        version: '1.0.0',
        migrationId: metrics.migrationId
      }
    }
  }

  private async executeActions(alert: Alert, actions: AlertAction[]): Promise<void> {
    for (const action of actions) {
      try {
        switch (action.type) {
          case 'log':
            await this.logAlert(alert, action.config)
            break
          case 'notify':
            await this.sendNotification(alert, action.config)
            break
          case 'pause':
            await this.pauseMigration(alert, action.config)
            break
          case 'rollback':
            await this.rollbackMigration(alert, action.config)
            break
          case 'scale':
            await this.scaleMigration(alert, action.config)
            break
        }
      } catch (error) {
        console.error(`Failed to execute alert action ${action.type}:`, error)
      }
    }
  }

  private async sendNotification(alert: Alert, config: any): Promise<void> {
    const message = this.formatAlertMessage(alert)

    if (config.channels?.includes('email')) {
      await this.sendEmailNotification({
        to: 'admin@example.com',
        subject: `Migration Alert: ${alert.name}`,
        body: message
      })
    }

    if (config.channels?.includes('slack')) {
      await this.sendSlackNotification({
        channel: '#migration-alerts',
        text: message,
        attachments: [{
          color: this.getSeverityColor(alert.severity),
          fields: [
            { title: 'Severity', value: alert.severity, short: true },
            { title: 'Timestamp', value: alert.timestamp.toISOString(), short: true }
          ]
        }]
      })
    }

    if (config.channels?.includes('sms')) {
      await this.sendSmsNotification({
        to: '+1234567890',
        message: `${alert.severity.toUpperCase()}: ${alert.name}`
      })
    }
  }

  private async pauseMigration(alert: Alert, config: any): Promise<void> {
    console.warn(`Pausing migration due to alert: ${alert.name}`)

    // å‘é€æš‚åœä¿¡å·ç»™è¿ç§»æ§åˆ¶å™¨
    await this.migrationController.pause({
      reason: config.reason,
      alertId: alert.id,
      timestamp: alert.timestamp
    })

    // è®°å½•æš‚åœäº‹ä»¶
    await this.eventLogger.logEvent({
      type: 'migration_paused',
      reason: config.reason,
      alertId: alert.id,
      severity: alert.severity
    })
  }
}
```

### 3. æ€§èƒ½åˆ†ææŠ¥å‘Š

#### 3.1 æ€§èƒ½æ•°æ®æ”¶é›†
```typescript
export class PerformanceAnalyzer {
  private measurements: PerformanceMeasurement[] = []
  private benchmarks: Map<string, Benchmark> = new Map()

  recordMeasurement(operation: string, duration: number, metadata?: any): void {
    const measurement: PerformanceMeasurement = {
      id: crypto.randomUUID(),
      operation,
      duration,
      timestamp: new Date(),
      metadata
    }

    this.measurements.push(measurement)

    // æ›´æ–°åŸºå‡†
    this.updateBenchmark(operation, duration)
  }

  getPerformanceReport(operation?: string): PerformanceReport {
    const filteredMeasurements = operation
      ? this.measurements.filter(m => m.operation === operation)
      : this.measurements

    if (filteredMeasurements.length === 0) {
      return {
        totalMeasurements: 0,
        averageDuration: 0,
        minDuration: 0,
        maxDuration: 0,
        percentiles: {},
        trends: [],
        anomalies: [],
        recommendations: []
      }
    }

    const durations = filteredMeasurements.map(m => m.duration).sort((a, b) => a - b)

    return {
      totalMeasurements: filteredMeasurements.length,
      averageDuration: this.calculateAverage(durations),
      minDuration: Math.min(...durations),
      maxDuration: Math.max(...durations),
      percentiles: this.calculatePercentiles(durations),
      trends: this.analyzeTrends(filteredMeasurements),
      anomalies: this.detectAnomalies(filteredMeasurements),
      recommendations: this.generateRecommendations(filteredMeasurements)
    }
  }

  private updateBenchmark(operation: string, duration: number): void {
    let benchmark = this.benchmarks.get(operation)

    if (!benchmark) {
      benchmark = {
        operation,
        measurements: [],
        baseline: null,
        threshold: null
      }
      this.benchmarks.set(operation, benchmark)
    }

    benchmark.measurements.push({
      duration,
      timestamp: new Date()
    })

    // æ›´æ–°åŸºå‡†çº¿ï¼ˆä½¿ç”¨æœ€è¿‘100æ¬¡æµ‹é‡çš„å¹³å‡å€¼ï¼‰
    if (benchmark.measurements.length >= 10) {
      const recentMeasurements = benchmark.measurements.slice(-100)
      const avgDuration = recentMeasurements.reduce((sum, m) => sum + m.duration, 0) / recentMeasurements.length
      benchmark.baseline = avgDuration
      benchmark.threshold = avgDuration * 2 // 2å€åŸºå‡†çº¿ä½œä¸ºé˜ˆå€¼
    }
  }

  private analyzeTrends(measurements: PerformanceMeasurement[]): TrendAnalysis[] {
    const groupedByOperation = this.groupByOperation(measurements)
    const trends: TrendAnalysis[] = []

    for (const [operation, opMeasurements] of groupedByOperation) {
      const sortedMeasurements = opMeasurements.sort((a, b) => a.timestamp.getTime() - b.timestamp.getTime())

      if (sortedMeasurements.length < 5) continue

      // è®¡ç®—è¶‹åŠ¿
      const durations = sortedMeasurements.map(m => m.duration)
      const trend = this.calculateTrend(durations)

      trends.push({
        operation,
        direction: trend > 0.1 ? 'increasing' : trend < -0.1 ? 'decreasing' : 'stable',
        slope: trend,
        confidence: this.calculateTrendConfidence(durations),
        timeRange: {
          start: sortedMeasurements[0].timestamp,
          end: sortedMeasurements[sortedMeasurements.length - 1].timestamp
        }
      })
    }

    return trends
  }

  private detectAnomalies(measurements: PerformanceMeasurement[]): Anomaly[] {
    const anomalies: Anomaly[] = []
    const groupedByOperation = this.groupByOperation(measurements)

    for (const [operation, opMeasurements] of groupedByOperation) {
      const benchmark = this.benchmarks.get(operation)
      if (!benchmark || !benchmark.threshold) continue

      for (const measurement of opMeasurements) {
        if (measurement.duration > benchmark.threshold) {
          anomalies.push({
            id: crypto.randomUUID(),
            type: 'performance_anomaly',
            severity: measurement.duration > benchmark.threshold * 3 ? 'high' : 'medium',
            measurement,
            benchmark: benchmark.threshold,
            deviation: (measurement.duration - benchmark.threshold) / benchmark.threshold
          })
        }
      }
    }

    return anomalies
  }

  private generateRecommendations(measurements: PerformanceMeasurement[]): Recommendation[] {
    const recommendations: Recommendation[] = []
    const groupedByOperation = this.groupByOperation(measurements)

    for (const [operation, opMeasurements] of groupedByOperation) {
      const durations = opMeasurements.map(m => m.duration)
      const avgDuration = durations.reduce((sum, d) => sum + d, 0) / durations.length
      const stdDev = this.calculateStandardDeviation(durations)

      // æ£€æŸ¥é«˜å˜å¼‚æ€§
      if (stdDev / avgDuration > 0.5) {
        recommendations.push({
          id: crypto.randomUUID(),
          type: 'variability',
          priority: 'medium',
          operation,
          message: `High variability detected in ${operation} operation (${(stdDev / avgDuration * 100).toFixed(1)}% CV)`,
          actions: [
            'Investigate environmental factors',
            'Consider caching strategies',
            'Optimize resource allocation'
          ]
        })
      }

      // æ£€æŸ¥æ€§èƒ½ä¸‹é™è¶‹åŠ¿
      const recentMeasurements = opMeasurements.slice(-20)
      const olderMeasurements = opMeasurements.slice(-40, -20)

      if (recentMeasurements.length >= 10 && olderMeasurements.length >= 10) {
        const recentAvg = recentMeasurements.reduce((sum, m) => sum + m.duration, 0) / recentMeasurements.length
        const olderAvg = olderMeasurements.reduce((sum, m) => sum + m.duration, 0) / olderMeasurements.length

        if (recentAvg > olderAvg * 1.2) {
          recommendations.push({
            id: crypto.randomUUID(),
            type: 'performance_degradation',
            priority: 'high',
            operation,
            message: `Performance degradation detected in ${operation} (${((recentAvg / olderAvg - 1) * 100).toFixed(1)}% increase)`,
            actions: [
              'Analyze recent code changes',
              'Check resource contention',
              'Review database queries'
            ]
          })
        }
      }
    }

    return recommendations
  }
}
```

## ğŸ› ï¸ å®æ–½å·¥å…·å’Œè„šæœ¬

### 1. æ•°æ®è¿ç§»å·¥å…·é›†

#### 1.1 è¿ç§»æ§åˆ¶å™¨
```typescript
// src/tools/migration-controller.ts
export class MigrationController {
  private migrator: DataMigration
  private monitor: MigrationMonitor
  private backupExecutor: BackupExecutor
  private alertProcessor: AlertProcessor

  constructor() {
    this.migrator = new DataMigration()
    this.monitor = new MigrationMonitor()
    this.backupExecutor = new BackupExecutor()
    this.alertProcessor = new AlertProcessor()
  }

  async executeMigration(options: MigrationOptions): Promise<MigrationResult> {
    console.log('Starting data migration with options:', options)

    try {
      // 1. å¼€å§‹ç›‘æ§
      this.monitor.startMonitoring()

      // 2. åˆ›å»ºè¿ç§»å‰å¤‡ä»½
      if (options.createBackup) {
        console.log('Creating pre-migration backup...')
        const backup = await this.backupExecutor.createFullBackup()
        console.log('Backup created:', backup.backupId)
      }

      // 3. æ‰§è¡Œè¿ç§»
      const result = await this.migrator.executeMigration(options)

      // 4. éªŒè¯è¿ç§»ç»“æœ
      const validation = await this.validateMigration(result)

      // 5. ç”ŸæˆæŠ¥å‘Š
      const report = await this.generateMigrationReport(result, validation)

      console.log('Migration completed successfully:', {
        recordsMigrated: result.recordsMigrated,
        duration: result.duration,
        validation: validation.isValid ? 'passed' : 'failed'
      })

      return {
        ...result,
        validation,
        report
      }
    } catch (error) {
      console.error('Migration failed:', error)

      // å¤„ç†è¿ç§»å¤±è´¥
      await this.handleMigrationFailure(error as Error, options)

      throw error
    } finally {
      this.monitor.stopMonitoring()
    }
  }

  async validateMigration(result: MigrationResult): Promise<MigrationValidation> {
    const validator = new DataValidator()

    const [dataConsistency, performanceValidation, integrityCheck] = await Promise.all([
      validator.checkDataConsistency(),
      validator.checkPerformanceMetrics(),
      validator.checkDataIntegrity()
    ])

    return {
      isValid: dataConsistency.isValid && performanceValidation.isValid && integrityCheck.isValid,
      dataConsistency,
      performanceValidation,
      integrityCheck,
      timestamp: new Date()
    }
  }

  async handleMigrationFailure(error: Error, options: MigrationOptions): Promise<void> {
    console.error('Handling migration failure:', error.message)

    // å‘é€å‘Šè­¦
    await this.alertProcessor.processMetrics(this.monitor.getMetrics())

    // å¦‚æœé…ç½®äº†è‡ªåŠ¨å›æ»š
    if (options.autoRollback) {
      console.log('Starting automatic rollback...')
      try {
        await this.rollbackMigration()
        console.log('Rollback completed successfully')
      } catch (rollbackError) {
        console.error('Rollback failed:', rollbackError)
        // å›æ»šå¤±è´¥æ—¶å¯åŠ¨ç´§æ€¥æ¢å¤
        await this.emergencyRecovery()
      }
    }
  }
}
```

#### 1.2 æ•°æ®éªŒè¯å·¥å…·
```typescript
// src/tools/data-validator.ts
export class DataValidator {
  async validateSourceData(source: DataSource): Promise<ValidationResult> {
    const result: ValidationResult = {
      isValid: true,
      errors: [],
      warnings: [],
      stats: null
    }

    try {
      // éªŒè¯æ•°æ®æºè¿æ¥
      await this.validateConnection(source)

      // éªŒè¯æ•°æ®ç»“æ„
      await this.validateDataStructure(source, result)

      // éªŒè¯æ•°æ®å®Œæ•´æ€§
      await this.validateDataIntegrity(source, result)

      // éªŒè¯ä¸šåŠ¡è§„åˆ™
      await this.validateBusinessRules(source, result)

      // æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
      result.stats = await this.collectStatistics(source)

      result.isValid = result.errors.length === 0

    } catch (error) {
      result.isValid = false
      result.errors.push({
        type: 'validation_error',
        message: `Validation failed: ${error.message}`,
        severity: 'critical'
      })
    }

    return result
  }

  async validateMigrationResult(
    source: DataSource,
    target: DataSource
  ): Promise<MigrationValidation> {
    const validation: MigrationValidation = {
      isValid: true,
      checks: [],
      summary: null
    }

    try {
      // æ£€æŸ¥è®°å½•æ•°ä¸€è‡´æ€§
      const recordCountCheck = await this.checkRecordCountConsistency(source, target)
      validation.checks.push(recordCountCheck)

      // æ£€æŸ¥æ•°æ®å†…å®¹ä¸€è‡´æ€§
      const contentCheck = await this.checkDataContentConsistency(source, target)
      validation.checks.push(contentCheck)

      // æ£€æŸ¥å…³ç³»å®Œæ•´æ€§
      const relationCheck = await this.checkRelationIntegrity(target)
      validation.checks.push(relationCheck)

      // æ£€æŸ¥ç´¢å¼•å®Œæ•´æ€§
      const indexCheck = await this.checkIndexIntegrity(target)
      validation.checks.push(indexCheck)

      // æ€§èƒ½åŸºå‡†æµ‹è¯•
      const performanceCheck = await this.runPerformanceBenchmarks(target)
      validation.checks.push(performanceCheck)

      validation.isValid = validation.checks.every(check => check.passed)
      validation.summary = this.generateValidationSummary(validation.checks)

    } catch (error) {
      validation.isValid = false
      validation.checks.push({
        name: 'validation_error',
        type: 'system',
        passed: false,
        message: `Migration validation failed: ${error.message}`,
        severity: 'critical'
      })
    }

    return validation
  }

  private async checkRecordCountConsistency(source: DataSource, target: DataSource): Promise<ValidationCheck> {
    const sourceStats = await this.collectStatistics(source)
    const targetStats = await this.collectStatistics(target)

    const checks: RecordCountCheck[] = []

    for (const table of Object.keys(sourceStats)) {
      const sourceCount = sourceStats[table]?.count || 0
      const targetCount = targetStats[table]?.count || 0
      const difference = Math.abs(sourceCount - targetCount)
      const tolerance = Math.max(1, sourceCount * 0.001) // 0.1% å®¹å·®

      checks.push({
        table,
        sourceCount,
        targetCount,
        difference,
        withinTolerance: difference <= tolerance
      })
    }

    const failedChecks = checks.filter(c => !c.withinTolerance)

    return {
      name: 'record_count_consistency',
      type: 'data',
      passed: failedChecks.length === 0,
      message: failedChecks.length === 0
        ? 'Record counts match between source and target'
        : `Record count mismatches in ${failedChecks.length} tables`,
      details: {
        totalTables: checks.length,
        mismatchedTables: failedChecks.length,
        checks
      },
      severity: failedChecks.length > 0 ? 'high' : 'info'
    }
  }

  private async checkDataContentConsistency(source: DataSource, target: DataSource): Promise<ValidationCheck> {
    const tables = await this.getTableNames(source)
    const contentChecks: ContentCheck[] = []

    for (const table of tables) {
      // å¯¹æ¯ä¸ªè¡¨è¿›è¡ŒæŠ½æ ·æ£€æŸ¥
      const sampleCheck = await this.checkTableContentSample(source, target, table)
      contentChecks.push(sampleCheck)
    }

    const failedChecks = contentChecks.filter(c => !c.matched)

    return {
      name: 'data_content_consistency',
      type: 'data',
      passed: failedChecks.length === 0,
      message: failedChecks.length === 0
        ? 'Data content consistency verified'
        : `Data content mismatches in ${failedChecks.length} tables`,
      details: {
        totalTables: contentChecks.length,
        mismatchedTables: failedChecks.length,
        checks: contentChecks
      },
      severity: failedChecks.length > 0 ? 'high' : 'info'
    }
  }
}
```

#### 1.3 æ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·
```typescript
// src/tools/performance-benchmark.ts
export class PerformanceBenchmark {
  private results: BenchmarkResult[] = []

  async runDatabaseBenchmarks(config: BenchmarkConfig): Promise<BenchmarkReport> {
    console.log('Starting database performance benchmarks...')

    const report: BenchmarkReport = {
      timestamp: new Date(),
      config,
      results: [],
      summary: null
    }

    try {
      // è¯»å–æ€§èƒ½åŸºå‡†
      await this.testReadPerformance(config, report)

      // å†™å…¥æ€§èƒ½åŸºå‡†
      await this.testWritePerformance(config, report)

      // æŸ¥è¯¢æ€§èƒ½åŸºå‡†
      await this.testQueryPerformance(config, report)

      // å¹¶å‘æ€§èƒ½åŸºå‡†
      await this.testConcurrentPerformance(config, report)

      // ç”Ÿæˆæ‘˜è¦
      report.summary = this.generateBenchmarkSummary(report.results)

      console.log('Benchmarks completed successfully')

      return report
    } catch (error) {
      console.error('Benchmarks failed:', error)
      throw error
    }
  }

  private async testReadPerformance(config: BenchmarkConfig, report: BenchmarkReport): Promise<void> {
    console.log('Testing read performance...')

    const testCases = [
      { name: 'single_record_read', iterations: 1000 },
      { name: 'batch_read_100', iterations: 100, batchSize: 100 },
      { name: 'indexed_query', iterations: 500 },
      { name: 'full_scan_query', iterations: 50 }
    ]

    for (const testCase of testCases) {
      const result = await this.runReadTest(testCase, config)
      report.results.push(result)
    }
  }

  private async testWritePerformance(config: BenchmarkConfig, report: BenchmarkReport): Promise<void> {
    console.log('Testing write performance...')

    const testCases = [
      { name: 'single_record_insert', iterations: 1000 },
      { name: 'batch_insert_100', iterations: 100, batchSize: 100 },
      { name: 'record_update', iterations: 500 },
      { name: 'record_delete', iterations: 500 }
    ]

    for (const testCase of testCases) {
      const result = await this.runWriteTest(testCase, config)
      report.results.push(result)
    }
  }

  private async runReadTest(testCase: ReadTestCase, config: BenchmarkConfig): Promise<BenchmarkResult> {
    const measurements: number[] = []
    const errors: Error[] = []

    console.log(`Running read test: ${testCase.name}`)

    for (let i = 0; i < testCase.iterations; i++) {
      try {
        const startTime = performance.now()

        // æ‰§è¡Œè¯»å–æ“ä½œ
        await this.executeReadOperation(testCase)

        const duration = performance.now() - startTime
        measurements.push(duration)

      } catch (error) {
        errors.push(error as Error)
      }
    }

    return this.processBenchmarkResults(testCase.name, 'read', measurements, errors)
  }

  private async runWriteTest(testCase: WriteTestCase, config: BenchmarkConfig): Promise<BenchmarkResult> {
    const measurements: number[] = []
    const errors: Error[] = []

    console.log(`Running write test: ${testCase.name}`)

    for (let i = 0; i < testCase.iterations; i++) {
      try {
        const startTime = performance.now()

        // æ‰§è¡Œå†™å…¥æ“ä½œ
        await this.executeWriteOperation(testCase)

        const duration = performance.now() - startTime
        measurements.push(duration)

      } catch (error) {
        errors.push(error as Error)
      }
    }

    return this.processBenchmarkResults(testCase.name, 'write', measurements, errors)
  }

  private processBenchmarkResults(
    testName: string,
    type: 'read' | 'write' | 'query' | 'concurrent',
    measurements: number[],
    errors: Error[]
  ): BenchmarkResult {
    const validMeasurements = measurements.filter(m => !isNaN(m) && m > 0)

    if (validMeasurements.length === 0) {
      return {
        testName,
        type,
        status: 'failed',
        successRate: 0,
        averageDuration: 0,
        minDuration: 0,
        maxDuration: 0,
        percentiles: {},
        errorRate: 1,
        errors: errors.map(e => e.message),
        timestamp: new Date()
      }
    }

    const sortedMeasurements = validMeasurements.sort((a, b) => a - b)

    return {
      testName,
      type,
      status: errors.length > measurements.length * 0.1 ? 'warning' : 'success',
      successRate: validMeasurements.length / measurements.length,
      averageDuration: this.calculateAverage(sortedMeasurements),
      minDuration: sortedMeasurements[0],
      maxDuration: sortedMeasurements[sortedMeasurements.length - 1],
      percentiles: this.calculatePercentiles(sortedMeasurements),
      errorRate: errors.length / measurements.length,
      errors: errors.map(e => e.message),
      timestamp: new Date()
    }
  }

  private generateBenchmarkSummary(results: BenchmarkResult[]): BenchmarkSummary {
    const passedTests = results.filter(r => r.status === 'success').length
    const warningTests = results.filter(r => r.status === 'warning').length
    const failedTests = results.filter(r => r.status === 'failed').length

    const overallStatus = failedTests === 0 ? 'success' : failedTests > passedTests ? 'failed' : 'warning'

    return {
      overallStatus,
      totalTests: results.length,
      passedTests,
      warningTests,
      failedTests,
      averageSuccessRate: results.reduce((sum, r) => sum + r.successRate, 0) / results.length,
      recommendations: this.generateBenchmarkRecommendations(results)
    }
  }
}
```

### 2. è‡ªåŠ¨åŒ–è„šæœ¬

#### 2.1 è¿ç§»å¯åŠ¨è„šæœ¬
```bash
#!/bin/bash

# scripts/start-migration.sh

set -e

echo "=== CardEverything Data Migration Script ==="
echo "Starting at: $(date)"

# åŠ è½½é…ç½®
source .env

# è®¾ç½®é»˜è®¤å€¼
MIGRATION_CONFIG=${MIGRATION_CONFIG:-"migration-config.json"}
BACKUP_ENABLED=${BACKUP_ENABLED:-"true"}
AUTO_ROLLBACK=${AUTO_ROLLBACK:-"true"}
DRY_RUN=${DRY_RUN:-"false"}

# æ£€æŸ¥å‰ç½®æ¡ä»¶
echo "Checking prerequisites..."

# æ£€æŸ¥Node.jsç‰ˆæœ¬
NODE_VERSION=$(node --version)
echo "Node.js version: $NODE_VERSION"

# æ£€æŸ¥å†…å­˜
AVAILABLE_MEMORY=$(free -m | awk 'NR==2{printf "%.2fGB", $7/1024}')
echo "Available memory: $AVAILABLE_MEMORY"

# æ£€æŸ¥ç£ç›˜ç©ºé—´
AVAILABLE_DISK=$(df -h . | awk 'NR==2{print $4}')
echo "Available disk space: $AVAILABLE_DISK"

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs/migration
LOG_FILE="logs/migration/migration-$(date +%Y%m%d_%H%M%S).log"

echo "Migration log will be written to: $LOG_FILE"

# éªŒè¯é…ç½®æ–‡ä»¶
if [ ! -f "$MIGRATION_CONFIG" ]; then
    echo "Error: Migration config file not found: $MIGRATION_CONFIG"
    exit 1
fi

# è¿è¡Œè¿ç§»
echo "Starting migration process..."

if [ "$DRY_RUN" = "true" ]; then
    echo "=== DRY RUN MODE ==="
    npm run migration:dry-run -- --config="$MIGRATION_CONFIG"
else
    npm run migration:start -- \
        --config="$MIGRATION_CONFIG" \
        --backup="$BACKUP_ENABLED" \
        --auto-rollback="$AUTO_ROLLBACK" \
        --log-file="$LOG_FILE"
fi

# æ£€æŸ¥ç»“æœ
MIGRATION_EXIT_CODE=$?

if [ $MIGRATION_EXIT_CODE -eq 0 ]; then
    echo "âœ… Migration completed successfully!"
    echo "Check the log file for details: $LOG_FILE"
else
    echo "âŒ Migration failed with exit code: $MIGRATION_EXIT_CODE"
    echo "Check the log file for error details: $LOG_FILE"

    if [ "$AUTO_ROLLBACK" = "true" ]; then
        echo "ğŸ”„ Starting automatic rollback..."
        npm run migration:rollback -- --log-file="$LOG_FILE"
    fi
fi

echo "Migration process finished at: $(date)"
exit $MIGRATION_EXIT_CODE
```

#### 2.2 å¥åº·æ£€æŸ¥è„šæœ¬
```bash
#!/bin/bash

# scripts/health-check.sh

set -e

echo "=== CardEverything Database Health Check ==="
echo "Checking at: $(date)"

# é…ç½®
HEALTH_CHECK_URL=${HEALTH_CHECK_URL:-"http://localhost:3000/api/health"}
TIMEOUT=${TIMEOUT:-30}
MAX_RETRIES=${MAX_RETRIES:-3}

# æ£€æŸ¥å‡½æ•°
check_health() {
    local attempt=1
    local max_attempts=$MAX_RETRIES

    while [ $attempt -le $max_attempts ]; do
        echo "Health check attempt $attempt/$max_attempts..."

        if curl -s -f --max-time $TIMEOUT "$HEALTH_CHECK_URL" > /dev/null; then
            echo "âœ… Health check passed!"
            return 0
        fi

        echo "âš ï¸  Health check failed, retrying in 5 seconds..."
        sleep 5
        ((attempt++))
    done

    echo "âŒ Health check failed after $max_attempts attempts"
    return 1
}

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
check_database() {
    echo "Checking database connectivity..."

    if npm run db:ping > /dev/null 2>&1; then
        echo "âœ… Database connection successful"
        return 0
    else
        echo "âŒ Database connection failed"
        return 1
    fi
}

# æ£€æŸ¥å­˜å‚¨ç©ºé—´
check_storage() {
    echo "Checking storage space..."

    local available_space=$(df -h . | awk 'NR==2{print $4}')
    local used_percent=$(df -h . | awk 'NR==2{print $5}' | sed 's/%//')

    echo "Available space: $available_space"
    echo "Used space: ${used_percent}%"

    if [ "$used_percent" -gt 90 ]; then
        echo "âš ï¸  Warning: Storage usage above 90%"
        return 1
    fi

    echo "âœ… Storage space is adequate"
    return 0
}

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
check_memory() {
    echo "Checking memory usage..."

    local used_percent=$(free | awk 'NR==2{printf "%.0f", $3/$2 * 100}')

    echo "Memory usage: ${used_percent}%"

    if [ "$used_percent" -gt 85 ]; then
        echo "âš ï¸  Warning: Memory usage above 85%"
        return 1
    fi

    echo "âœ… Memory usage is normal"
    return 0
}

# ä¸»æ£€æŸ¥æµç¨‹
main() {
    local exit_code=0

    echo "Starting comprehensive health check..."

    # æ•°æ®åº“æ£€æŸ¥
    if ! check_database; then
        exit_code=1
    fi

    # å­˜å‚¨æ£€æŸ¥
    if ! check_storage; then
        exit_code=1
    fi

    # å†…å­˜æ£€æŸ¥
    if ! check_memory; then
        exit_code=1
    fi

    # åº”ç”¨å¥åº·æ£€æŸ¥
    if ! check_health; then
        exit_code=1
    fi

    if [ $exit_code -eq 0 ]; then
        echo "ğŸ‰ All health checks passed!"
    else
        echo "âŒ Some health checks failed"
    fi

    return $exit_code
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

#### 2.3 å¤‡ä»½ç®¡ç†è„šæœ¬
```bash
#!/bin/bash

# scripts/backup-manager.sh

set -e

echo "=== CardEverything Backup Manager ==="
echo "Running at: $(date)"

# é…ç½®
BACKUP_DIR=${BACKUP_DIR:-"./backups"}
MAX_BACKUPS=${MAX_BACKUPS:-30}
COMPRESSION_ENABLED=${COMPRESSION_ENABLED:-"true"}
ENCRYPTION_ENABLED=${ENCRYPTION_ENABLED:-"true"}
BACKUP_RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-30}

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR"
mkdir -p "$BACKUP_DIR/full"
mkdir -p "$BACKUP_DIR/incremental"
mkdir -p "$BACKUP_DIR/rollback"

# å¤‡ä»½å‡½æ•°
create_backup() {
    local backup_type=$1
    local backup_name="backup-$(date +%Y%m%d_%H%M%S)-${backup_type}"
    local backup_path="$BACKUP_DIR/${backup_type}/${backup_name}"

    echo "Creating $backup_type backup: $backup_name"

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    local temp_dir=$(mktemp -d)

    # å¯¼å‡ºæ•°æ®
    case $backup_type in
        "full")
            npm run db:export -- --output="$temp_dir/data.json" --format=json
            ;;
        "incremental")
            npm run db:export-incremental -- --output="$temp_dir/data.json" --since="$LAST_BACKUP_TIME"
            ;;
        "rollback")
            npm run db:export -- --output="$temp_dir/data.json" --format=json --include-metadata
            ;;
    esac

    # å‹ç¼©
    if [ "$COMPRESSION_ENABLED" = "true" ]; then
        echo "Compressing backup..."
        tar -czf "$backup_path.tar.gz" -C "$temp_dir" .
    else
        mv "$temp_dir" "$backup_path"
    fi

    # åŠ å¯†
    if [ "$ENCRYPTION_ENABLED" = "true" ]; then
        echo "Encrypting backup..."
        gpg --symmetric --cipher-algo AES256 --output "$backup_path.tar.gz.gpg" "$backup_path.tar.gz"
        rm "$backup_path.tar.gz"
        backup_path="$backup_path.tar.gz.gpg"
    fi

    # è®¡ç®—æ ¡éªŒå’Œ
    local checksum=$(sha256sum "$backup_path" | cut -d' ' -f1)
    echo "$checksum" > "$backup_path.sha256"

    # æ¸…ç†ä¸´æ—¶ç›®å½•
    rm -rf "$temp_dir"

    echo "âœ… Backup created: $backup_path"
    echo "Checksum: $checksum"

    # æ›´æ–°æœ€åå¤‡ä»½æ—¶é—´
    LAST_BACKUP_TIME=$(date -Iseconds)
    export LAST_BACKUP_TIME
}

# æ¸…ç†æ—§å¤‡ä»½
cleanup_old_backups() {
    echo "Cleaning up old backups..."

    # æ¸…ç†å®Œæ•´å¤‡ä»½
    find "$BACKUP_DIR/full" -name "backup-*.tar.gz*" -mtime +$BACKUP_RETENTION_DAYS -delete

    # æ¸…ç†å¢é‡å¤‡ä»½
    find "$BACKUP_DIR/incremental" -name "backup-*.tar.gz*" -mtime +7 -delete

    # æ¸…ç†å›æ»šå¤‡ä»½
    find "$BACKUP_DIR/rollback" -name "backup-*.tar.gz*" -mtime +30 -delete

    # é™åˆ¶å¤‡ä»½æ•°é‡
    for backup_type in full incremental rollback; do
        local backup_count=$(ls -1 "$BACKUP_DIR/$backup_type/"*.tar.gz* 2>/dev/null | wc -l)
        if [ "$backup_count" -gt "$MAX_BACKUPS" ]; then
            echo "Removing old $backup_type backups (keeping $MAX_BACKUPS)"
            ls -t "$BACKUP_DIR/$backup_type/"*.tar.gz* | tail -n +$(($MAX_BACKUPS + 1)) | xargs rm -f
        fi
    done

    echo "âœ… Backup cleanup completed"
}

# éªŒè¯å¤‡ä»½
verify_backup() {
    local backup_path=$1

    echo "Verifying backup: $backup_path"

    # æ£€æŸ¥æ ¡éªŒå’Œ
    if [ -f "$backup_path.sha256" ]; then
        local expected_checksum=$(cat "$backup_path.sha256")
        local actual_checksum=$(sha256sum "$backup_path" | cut -d' ' -f1)

        if [ "$expected_checksum" != "$actual_checksum" ]; then
            echo "âŒ Backup verification failed: checksum mismatch"
            return 1
        fi
    fi

    # å¦‚æœæ˜¯åŠ å¯†å¤‡ä»½ï¼Œè§£å¯†å¹¶éªŒè¯å†…å®¹
    if [[ "$backup_path" == *.gpg ]]; then
        local temp_file=$(mktemp)
        gpg --quiet --decrypt --output "$temp_file" "$backup_path"

        if [ ! -s "$temp_file" ]; then
            echo "âŒ Backup verification failed: decryption failed"
            rm -f "$temp_file"
            return 1
        fi

        rm -f "$temp_file"
    fi

    echo "âœ… Backup verification passed"
    return 0
}

# åˆ—å‡ºå¤‡ä»½
list_backups() {
    echo "Available backups:"
    echo "=================="

    for backup_type in full incremental rollback; do
        echo -e "\n$backup_type backups:"
        find "$BACKUP_DIR/$backup_type" -name "backup-*.tar.gz*" -printf "%T+ %p\n" | sort -r | head -10
    done
}

# ä¸»èœå•
case "${1:-}" in
    "full")
        create_backup "full"
        cleanup_old_backups
        ;;
    "incremental")
        create_backup "incremental"
        ;;
    "rollback")
        create_backup "rollback"
        ;;
    "cleanup")
        cleanup_old_backups
        ;;
    "verify")
        if [ -z "$2" ]; then
            echo "Error: Please specify backup path to verify"
            exit 1
        fi
        verify_backup "$2"
        ;;
    "list")
        list_backups
        ;;
    "status")
        echo "Backup Status:"
        echo "============="
        echo "Backup directory: $BACKUP_DIR"
        echo "Max backups: $MAX_BACKUPS"
        echo "Compression: $COMPRESSION_ENABLED"
        echo "Encryption: $ENCRYPTION_ENABLED"
        echo "Retention days: $BACKUP_RETENTION_DAYS"
        list_backups
        ;;
    *)
        echo "Usage: $0 {full|incremental|rollback|cleanup|verify|list|status}"
        echo ""
        echo "Commands:"
        echo "  full           - Create full backup"
        echo "  incremental    - Create incremental backup"
        echo "  rollback       - Create rollback backup"
        echo "  cleanup        - Clean old backups"
        echo "  verify <path>  - Verify backup integrity"
        echo "  list           - List available backups"
        echo "  status         - Show backup status"
        exit 1
        ;;
esac

echo "Backup manager completed at: $(date)"
```

### 3. ç›‘æ§å’ŒæŠ¥å‘Šå·¥å…·

#### 3.1 è¿ç§»ç›‘æ§ä»ªè¡¨æ¿
```typescript
// src/tools/migration-dashboard.ts
export class MigrationDashboard {
  private server: any
  private socketServer: any
  private metricsStore: MetricsStore

  constructor() {
    this.metricsStore = new MetricsStore()
  }

  async start(port: number = 3001): Promise<void> {
    const express = require('express')
    const http = require('http')
    const socketIo = require('socket.io')

    const app = express()
    this.server = http.createServer(app)
    this.socketServer = new socketIo.Server(this.server, {
      cors: { origin: "*" }
    })

    // ä¸­é—´ä»¶
    app.use(express.json())
    app.use(express.static('public'))

    // APIè·¯ç”±
    this.setupApiRoutes(app)

    // WebSocketäº‹ä»¶
    this.setupWebSocketEvents()

    // å¯åŠ¨æœåŠ¡å™¨
    this.server.listen(port, () => {
      console.log(`Migration dashboard running on port ${port}`)
      console.log(`Access at: http://localhost:${port}`)
    })
  }

  private setupApiRoutes(app: any): void {
    // è·å–è¿ç§»çŠ¶æ€
    app.get('/api/migration/status', async (req, res) => {
      try {
        const status = await this.metricsStore.getLatestStatus()
        res.json(status)
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })

    // è·å–æ€§èƒ½æŒ‡æ ‡
    app.get('/api/migration/metrics', async (req, res) => {
      try {
        const metrics = await this.metricsStore.getMetrics()
        res.json(metrics)
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })

    // è·å–å‘Šè­¦å†å²
    app.get('/api/migration/alerts', async (req, res) => {
      try {
        const alerts = await this.metricsStore.getAlerts()
        res.json(alerts)
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })

    // è·å–æ€§èƒ½æŠ¥å‘Š
    app.get('/api/migration/report', async (req, res) => {
      try {
        const report = await this.generatePerformanceReport()
        res.json(report)
      } catch (error) {
        res.status(500).json({ error: error.message })
      }
    })

    // å¥åº·æ£€æŸ¥
    app.get('/health', (req, res) => {
      res.json({ status: 'healthy', timestamp: new Date().toISOString() })
    })
  }

  private setupWebSocketEvents(): void {
    this.socketServer.on('connection', (socket: any) => {
      console.log('Dashboard client connected')

      // å‘é€å½“å‰çŠ¶æ€
      this.sendCurrentStatus(socket)

      // è®¢é˜…å®æ—¶æ›´æ–°
      socket.on('subscribe', (data: any) => {
        console.log('Client subscribed to updates:', data)
        socket.join('migration-updates')
      })

      // å¤„ç†æ–­å¼€è¿æ¥
      socket.on('disconnect', () => {
        console.log('Dashboard client disconnected')
      })
    })
  }

  async updateMetrics(metrics: MigrationMetrics): Promise<void> {
    // å­˜å‚¨æŒ‡æ ‡
    await this.metricsStore.storeMetrics(metrics)

    // å¹¿æ’­ç»™æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯
    this.socketServer.to('migration-updates').emit('metrics-update', metrics)

    // æ£€æŸ¥å‘Šè­¦æ¡ä»¶
    await this.checkAlertConditions(metrics)
  }

  async sendAlert(alert: Alert): Promise<void> {
    // å­˜å‚¨å‘Šè­¦
    await this.metricsStore.storeAlert(alert)

    // å¹¿æ’­å‘Šè­¦
    this.socketServer.emit('alert', alert)

    // å‘é€é€šçŸ¥
    await this.sendNotification(alert)
  }

  private async sendCurrentStatus(socket: any): Promise<void> {
    try {
      const [status, metrics, alerts] = await Promise.all([
        this.metricsStore.getLatestStatus(),
        this.metricsStore.getMetrics(),
        this.metricsStore.getAlerts()
      ])

      socket.emit('initial-data', { status, metrics, alerts })
    } catch (error) {
      console.error('Failed to send initial data:', error)
    }
  }

  private async checkAlertConditions(metrics: MigrationMetrics): Promise<void> {
    const conditions = [
      { metric: 'errorRate', threshold: 0.1, severity: 'critical' },
      { metric: 'memoryUsage', threshold: 0.9, severity: 'critical' },
      { metric: 'duration', threshold: 7200000, severity: 'warning' }
    ]

    for (const condition of conditions) {
      if (metrics[condition.metric] > condition.threshold) {
        const alert: Alert = {
          id: crypto.randomUUID(),
          type: 'threshold_exceeded',
          severity: condition.severity,
          message: `${condition.metric} exceeded threshold: ${metrics[condition.metric]} > ${condition.threshold}`,
          timestamp: new Date(),
          metrics
        }

        await this.sendAlert(alert)
      }
    }
  }
}
```

## ğŸ“ˆ å®æ–½æ—¶é—´è¡¨å’Œé‡Œç¨‹ç¢‘

### 1. å®æ–½é˜¶æ®µåˆ’åˆ†

#### ç¬¬ä¸€é˜¶æ®µï¼šå‡†å¤‡å’Œè§„åˆ’ï¼ˆ1å‘¨ï¼‰
**ç›®æ ‡ï¼š** å®Œæˆæ‰€æœ‰å‡†å¤‡å·¥ä½œï¼Œç¡®ä¿è¿ç§»é¡ºåˆ©è¿›è¡Œ

**ä»»åŠ¡æ¸…å•ï¼š**
- [ ] æ•°æ®åº“æ¶æ„åˆ†æå®Œæˆ
- [ ] è¿ç§»ç­–ç•¥æ–‡æ¡£å®¡æ ¸
- [ ] ç¯å¢ƒå‡†å¤‡å’Œå·¥å…·é…ç½®
- [ ] å¤‡ä»½ç­–ç•¥éªŒè¯
- [ ] å›¢é˜ŸåŸ¹è®­å’ŒæŠ€æœ¯å‡†å¤‡

**äº¤ä»˜ç‰©ï¼š**
- æ•°æ®è¿ç§»ç­–ç•¥æ–‡æ¡£ (v1.0)
- ç¯å¢ƒé…ç½®æ–‡ä»¶å’Œè„šæœ¬
- å¤‡ä»½å’Œæ¢å¤æµ‹è¯•æŠ¥å‘Š
- å›¢é˜ŸåŸ¹è®­ææ–™

#### ç¬¬äºŒé˜¶æ®µï¼šå·¥å…·å¼€å‘å’Œæµ‹è¯•ï¼ˆ2å‘¨ï¼‰
**ç›®æ ‡ï¼š** å¼€å‘æ‰€æœ‰å¿…è¦çš„è¿ç§»å·¥å…·å’ŒéªŒè¯æœºåˆ¶

**ä»»åŠ¡æ¸…å•ï¼š**
- [ ] æ•°æ®è¿ç§»æ§åˆ¶å™¨å¼€å‘
- [ ] æ•°æ®éªŒè¯å·¥å…·å¼€å‘
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·å¼€å‘
- [ ] ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿå¼€å‘
- [ ] è‡ªåŠ¨åŒ–è„šæœ¬ç¼–å†™
- [ ] å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•

**äº¤ä»˜ç‰©ï¼š**
- è¿ç§»å·¥å…·å¥—ä»¶
- æµ‹è¯•ç”¨ä¾‹å’Œæµ‹è¯•æŠ¥å‘Š
- è‡ªåŠ¨åŒ–è„šæœ¬åº“
- ç›‘æ§ä»ªè¡¨æ¿

#### ç¬¬ä¸‰é˜¶æ®µï¼šè¿ç§»æ‰§è¡Œå’ŒéªŒè¯ï¼ˆ1å‘¨ï¼‰
**ç›®æ ‡ï¼š** æ‰§è¡Œæ•°æ®è¿ç§»å¹¶è¿›è¡Œå…¨é¢éªŒè¯

**ä»»åŠ¡æ¸…å•ï¼š**
- [ ] ç”Ÿäº§ç¯å¢ƒå¤‡ä»½
- [ ] è¿ç§»é¢„æ¼”ï¼ˆåœ¨æµ‹è¯•ç¯å¢ƒï¼‰
- [ ] ç”Ÿäº§ç¯å¢ƒè¿ç§»æ‰§è¡Œ
- [ ] æ•°æ®å®Œæ•´æ€§éªŒè¯
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] ç”¨æˆ·éªŒæ”¶æµ‹è¯•

**äº¤ä»˜ç‰©ï¼š**
- è¿ç§»æ‰§è¡ŒæŠ¥å‘Š
- æ•°æ®éªŒè¯æŠ¥å‘Š
- æ€§èƒ½æµ‹è¯•æŠ¥å‘Š
- ç”¨æˆ·éªŒæ”¶æµ‹è¯•æŠ¥å‘Š

#### ç¬¬å››é˜¶æ®µï¼šä¼˜åŒ–å’Œæ–‡æ¡£ï¼ˆ1å‘¨ï¼‰
**ç›®æ ‡ï¼š** ä¼˜åŒ–è¿ç§»ç»“æœï¼Œå®Œå–„æ–‡æ¡£å’ŒåŸ¹è®­

**ä»»åŠ¡æ¸…å•ï¼š**
- [ ] æ€§èƒ½è°ƒä¼˜
- [ ] é—®é¢˜ä¿®å¤
- [ ] æ–‡æ¡£å®Œå–„
- [ ] ç”¨æˆ·åŸ¹è®­
- [ ] è¿ç»´äº¤æ¥

**äº¤ä»˜ç‰©ï¼š**
- ä¼˜åŒ–æŠ¥å‘Š
- å®Œæ•´æŠ€æœ¯æ–‡æ¡£
- ç”¨æˆ·åŸ¹è®­ææ–™
- è¿ç»´æ‰‹å†Œ

### 2. å…³é”®é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | æ—¶é—´ | æè¿° | æˆåŠŸæ ‡å‡† |
|--------|------|------|----------|
| M1: æ¶æ„åˆ†æå®Œæˆ | ç¬¬1å‘¨æœ« | å®Œæˆç°æœ‰æ¶æ„åˆ†æï¼Œç¡®å®šè¿ç§»ç­–ç•¥ | åˆ†ææŠ¥å‘Šå®¡æ ¸é€šè¿‡ï¼Œè¿ç§»ç­–ç•¥ç¡®å®š |
| M2: å·¥å…·å¼€å‘å®Œæˆ | ç¬¬3å‘¨æœ« | æ‰€æœ‰è¿ç§»å·¥å…·å¼€å‘å®Œæˆå¹¶é€šè¿‡æµ‹è¯• | å·¥å…·åŠŸèƒ½å®Œæ•´ï¼Œæµ‹è¯•è¦†ç›–ç‡ > 95% |
| M3: æµ‹è¯•ç¯å¢ƒéªŒè¯ | ç¬¬4å‘¨æœ« | åœ¨æµ‹è¯•ç¯å¢ƒå®Œæˆè¿ç§»éªŒè¯ | æµ‹è¯•ç¯å¢ƒè¿ç§»æˆåŠŸï¼ŒéªŒè¯é€šè¿‡ |
| M4: ç”Ÿäº§ç¯å¢ƒå‡†å¤‡ | ç¬¬5å‘¨ä¸­ | ç”Ÿäº§ç¯å¢ƒå‡†å¤‡å°±ç»ªï¼Œå¤‡ä»½å®Œæˆ | å¤‡ä»½éªŒè¯é€šè¿‡ï¼Œç¯å¢ƒå°±ç»ª |
| M5: ç”Ÿäº§ç¯å¢ƒè¿ç§» | ç¬¬5å‘¨æœ« | æ‰§è¡Œç”Ÿäº§ç¯å¢ƒæ•°æ®è¿ç§» | è¿ç§»æˆåŠŸï¼Œæ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡ |
| M6: é¡¹ç›®äº¤ä»˜ | ç¬¬6å‘¨æœ« | é¡¹ç›®å®Œæˆï¼Œæ–‡æ¡£äº¤ä»˜ | æ‰€æœ‰äº¤ä»˜ç‰©å®Œæˆï¼Œç”¨æˆ·åŸ¹è®­å®Œæˆ |

### 3. èµ„æºéœ€æ±‚

#### 3.1 äººåŠ›èµ„æº
- **æ•°æ®åº“æ¶æ„å¸ˆ**: 1äººï¼ˆå…¨ç¨‹ï¼‰
- **åç«¯å¼€å‘å·¥ç¨‹å¸ˆ**: 2äººï¼ˆç¬¬2-3å‘¨ï¼‰
- **æµ‹è¯•å·¥ç¨‹å¸ˆ**: 1äººï¼ˆç¬¬2-4å‘¨ï¼‰
- **è¿ç»´å·¥ç¨‹å¸ˆ**: 1äººï¼ˆç¬¬4-6å‘¨ï¼‰
- **é¡¹ç›®ç»ç†**: 1äººï¼ˆå…¨ç¨‹ï¼‰

#### 3.2 æŠ€æœ¯èµ„æº
- **å¼€å‘ç¯å¢ƒ**: Node.js 18+, TypeScript 5+
- **æµ‹è¯•ç¯å¢ƒ**: ä¸ç”Ÿäº§ç¯å¢ƒé…ç½®ç›¸åŒ
- **å­˜å‚¨èµ„æº**: è‡³å°‘2å€å½“å‰æ•°æ®é‡çš„å­˜å‚¨ç©ºé—´
- **ç½‘ç»œèµ„æº**: ç¨³å®šçš„ç½‘ç»œè¿æ¥
- **ç›‘æ§å·¥å…·**: å®æ—¶ç›‘æ§ç³»ç»Ÿ

#### 3.3 æ—¶é—´èµ„æº
- **æ€»å·¥æœŸ**: 6å‘¨
- **å…³é”®è·¯å¾„**: å·¥å…·å¼€å‘ â†’ æµ‹è¯•éªŒè¯ â†’ ç”Ÿäº§è¿ç§»
- **ç¼“å†²æ—¶é—´**: æ¯ä¸ªé˜¶æ®µé¢„ç•™1-2å¤©ç¼“å†²æ—¶é—´

## ğŸ” é£é™©è¯„ä¼°å’Œç¼“è§£æªæ–½

### 1. æŠ€æœ¯é£é™©è¯„ä¼°

#### 1.1 æ•°æ®ä¸¢å¤±é£é™©
**é£é™©ç­‰çº§**: é«˜
**å½±å“**: æ•°æ®æ°¸ä¹…ä¸¢å¤±ï¼Œä¸šåŠ¡ä¸­æ–­
**æ¦‚ç‡**: ä½ï¼ˆ< 5%ï¼‰
**ç¼“è§£æªæ–½**:
- è¿ç§»å‰åˆ›å»ºå®Œæ•´å¤‡ä»½
- ä½¿ç”¨äº‹åŠ¡æ€§è¿ç§»æœºåˆ¶
- å®æ—¶æ•°æ®éªŒè¯
- å¿«é€Ÿå›æ»šæœºåˆ¶

#### 1.2 æ€§èƒ½ä¸‹é™é£é™©
**é£é™©ç­‰çº§**: ä¸­
**å½±å“**: ç”¨æˆ·ä½“éªŒä¸‹é™ï¼Œç³»ç»Ÿå“åº”å˜æ…¢
**æ¦‚ç‡**: ä¸­ï¼ˆ20-30%ï¼‰
**ç¼“è§£æªæ–½**:
- è¿ç§»å‰æ€§èƒ½åŸºå‡†æµ‹è¯•
- ä¼˜åŒ–çš„ç´¢å¼•è®¾è®¡
- åˆ†æ‰¹å¤„ç†ç­–ç•¥
- æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

#### 1.3 å…¼å®¹æ€§é—®é¢˜é£é™©
**é£é™©ç­‰çº§**: ä¸­
**å½±å“**: åŠŸèƒ½ä¸å¯ç”¨ï¼Œæ•°æ®æ ¼å¼é”™è¯¯
**æ¦‚ç‡**: ä¸­ï¼ˆ15-25%ï¼‰
**ç¼“è§£æªæ–½**:
- å…¨é¢çš„å…¼å®¹æ€§æµ‹è¯•
- å‘åå…¼å®¹å±‚è®¾è®¡
- æ•°æ®æ ¼å¼éªŒè¯
- æ¸è¿›å¼éƒ¨ç½²ç­–ç•¥

### 2. è¿è¥é£é™©è¯„ä¼°

#### 2.1 ä¸šåŠ¡ä¸­æ–­é£é™©
**é£é™©ç­‰çº§**: é«˜
**å½±å“**: ä¸šåŠ¡æœåŠ¡ä¸å¯ç”¨ï¼Œç”¨æˆ·å—å½±å“
**æ¦‚ç‡**: ä½ï¼ˆ< 10%ï¼‰
**ç¼“è§£æªæ–½**:
- é›¶åœæœºè¿ç§»ç­–ç•¥
- è“ç»¿éƒ¨ç½²æ¨¡å¼
- å¿«é€Ÿå›æ»šèƒ½åŠ›
- ç”¨æˆ·é€šçŸ¥æœºåˆ¶

#### 2.2 å›¢é˜ŸæŠ€èƒ½é£é™©
**é£é™©ç­‰çº§**: ä¸­
**å½±å“**: è¿ç§»è¿›åº¦å»¶è¿Ÿï¼Œè´¨é‡é—®é¢˜
**æ¦‚ç‡**: ä¸­ï¼ˆ20-30%ï¼‰
**ç¼“è§£æªæ–½**:
- å›¢é˜ŸåŸ¹è®­å’ŒæŠ€æœ¯å‡†å¤‡
- ä¸“å®¶æ”¯æŒå’Œå’¨è¯¢
- è¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£
- çŸ¥è¯†å…±äº«æœºåˆ¶

#### 2.3 æ—¶é—´å‹åŠ›é£é™©
**é£é™©ç­‰çº§**: ä¸­
**å½±å“**: è´¨é‡ä¸‹é™ï¼Œæµ‹è¯•ä¸å……åˆ†
**æ¦‚ç‡**: é«˜ï¼ˆ40-50%ï¼‰
**ç¼“è§£æªæ–½**:
- åˆç†çš„é¡¹ç›®è®¡åˆ’
- é‡Œç¨‹ç¢‘ç®¡ç†
- èµ„æºé¢„ç•™
- é£é™©ç¼“å†²æ—¶é—´

### 3. é£é™©åº”å¯¹ç­–ç•¥

#### 3.1 é¢„é˜²æ€§æªæ–½
- **å……åˆ†æµ‹è¯•**: åœ¨æµ‹è¯•ç¯å¢ƒè¿›è¡Œå…¨é¢çš„è¿ç§»æµ‹è¯•
- **å¤‡ä»½éªŒè¯**: éªŒè¯æ‰€æœ‰å¤‡ä»½çš„å®Œæ•´æ€§å’Œå¯æ¢å¤æ€§
- **æ–‡æ¡£å®Œå–„**: ç¡®ä¿æ‰€æœ‰æŠ€æœ¯æ–‡æ¡£å’Œæ“ä½œæ‰‹å†Œå®Œæ•´
- **åŸ¹è®­åˆ°ä½**: ç¡®ä¿å›¢é˜Ÿæˆå‘˜å…·å¤‡å¿…è¦çš„æŠ€èƒ½

#### 3.2 æ£€æµ‹æªæ–½
- **å®æ—¶ç›‘æ§**: éƒ¨ç½²å…¨é¢çš„ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ
- **æ€§èƒ½æŒ‡æ ‡**: ç›‘æ§å…³é”®æ€§èƒ½æŒ‡æ ‡çš„å˜åŒ–
- **ç”¨æˆ·åé¦ˆ**: æ”¶é›†ç”¨æˆ·ä½“éªŒåé¦ˆ
- **æ—¥å¿—åˆ†æ**: å®æ—¶åˆ†æç³»ç»Ÿæ—¥å¿—

#### 3.3 å“åº”æªæ–½
- **å¿«é€Ÿå›æ»š**: å‡†å¤‡å¥½å¿«é€Ÿå›æ»šæœºåˆ¶
- **ä¸“å®¶æ”¯æŒ**: å»ºç«‹ä¸“å®¶æ”¯æŒå›¢é˜Ÿ
- **æ²Ÿé€šæœºåˆ¶**: å»ºç«‹æœ‰æ•ˆçš„æ²Ÿé€šå’ŒæŠ¥å‘Šæœºåˆ¶
- **åº”æ€¥æµç¨‹**: åˆ¶å®šè¯¦ç»†çš„åº”æ€¥å“åº”æµç¨‹

## ğŸ“‹ æµ‹è¯•éªŒè¯ç­–ç•¥

### 1. æµ‹è¯•ç±»å‹å’Œè¦†ç›–èŒƒå›´

#### 1.1 å•å…ƒæµ‹è¯•
**ç›®æ ‡**: éªŒè¯å„ä¸ªç»„ä»¶çš„åŠŸèƒ½æ­£ç¡®æ€§
**è¦†ç›–èŒƒå›´**: 95%+
**æµ‹è¯•å†…å®¹**:
- æ•°æ®è¿ç§»æ ¸å¿ƒé€»è¾‘
- æ•°æ®éªŒè¯ç®—æ³•
- æ€§èƒ½ç›‘æ§ç»„ä»¶
- å‘Šè­¦å¤„ç†é€»è¾‘

#### 1.2 é›†æˆæµ‹è¯•
**ç›®æ ‡**: éªŒè¯ç»„ä»¶ä¹‹é—´çš„äº¤äº’æ­£ç¡®æ€§
**è¦†ç›–èŒƒå›´**: 90%+
**æµ‹è¯•å†…å®¹**:
- å®Œæ•´è¿ç§»æµç¨‹
- æ•°æ®å¤‡ä»½å’Œæ¢å¤
- ç›‘æ§å’Œå‘Šè­¦é›†æˆ
- ç”¨æˆ·æ¥å£é›†æˆ

#### 1.3 æ€§èƒ½æµ‹è¯•
**ç›®æ ‡**: éªŒè¯ç³»ç»Ÿæ€§èƒ½æ»¡è¶³è¦æ±‚
**æµ‹è¯•åœºæ™¯**:
- æ­£å¸¸è´Ÿè½½ä¸‹çš„æ€§èƒ½
- é«˜å¹¶å‘åœºæ™¯ä¸‹çš„æ€§èƒ½
- å¤§æ•°æ®é‡å¤„ç†æ€§èƒ½
- é•¿æ—¶é—´è¿è¡Œçš„ç¨³å®šæ€§

#### 1.4 å®‰å…¨æµ‹è¯•
**ç›®æ ‡**: éªŒè¯æ•°æ®å®‰å…¨å’Œè®¿é—®æ§åˆ¶
**æµ‹è¯•å†…å®¹**:
- æ•°æ®åŠ å¯†æœ‰æ•ˆæ€§
- è®¿é—®æ§åˆ¶æœºåˆ¶
- å¤‡ä»½æ•°æ®å®‰å…¨æ€§
- æ¢å¤è¿‡ç¨‹å®‰å…¨æ€§

### 2. æµ‹è¯•ç¯å¢ƒè¦æ±‚

#### 2.1 æµ‹è¯•ç¯å¢ƒé…ç½®
- **ç¡¬ä»¶é…ç½®**: ä¸ç”Ÿäº§ç¯å¢ƒç›¸ä¼¼æˆ–æ›´é«˜é…ç½®
- **è½¯ä»¶ç‰ˆæœ¬**: ä¸ç”Ÿäº§ç¯å¢ƒå®Œå…¨ä¸€è‡´
- **ç½‘ç»œç¯å¢ƒ**: æ¨¡æ‹Ÿç”Ÿäº§ç½‘ç»œæ¡ä»¶
- **æ•°æ®è§„æ¨¡**: ä½¿ç”¨çœŸå®æ•°æ®æˆ–ç­‰é‡æµ‹è¯•æ•°æ®

#### 2.2 æµ‹è¯•æ•°æ®ç®¡ç†
- **æ•°æ®è„±æ•**: æ•æ„Ÿæ•°æ®è„±æ•å¤„ç†
- **æ•°æ®è§„æ¨¡**: è‡³å°‘1ä¸‡æ¡è®°å½•
- **æ•°æ®å¤šæ ·æ€§**: åŒ…å«å„ç§è¾¹ç•Œæƒ…å†µ
- **æ•°æ®éªŒè¯**: æµ‹è¯•æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§

### 3. æµ‹è¯•æ‰§è¡Œè®¡åˆ’

#### 3.1 æµ‹è¯•é˜¶æ®µå®‰æ’
| é˜¶æ®µ | æ—¶é—´ | æµ‹è¯•ç±»å‹ | ä¸»è¦å†…å®¹ |
|------|------|----------|----------|
| å•å…ƒæµ‹è¯• | ç¬¬2å‘¨ | å•å…ƒæµ‹è¯• | ç»„ä»¶åŠŸèƒ½æµ‹è¯• |
| é›†æˆæµ‹è¯• | ç¬¬3å‘¨ | é›†æˆæµ‹è¯• | ç»„ä»¶äº¤äº’æµ‹è¯• |
| æ€§èƒ½æµ‹è¯• | ç¬¬4å‘¨ | æ€§èƒ½æµ‹è¯• | æ€§èƒ½åŸºå‡†æµ‹è¯• |
| å®‰å…¨æµ‹è¯• | ç¬¬4å‘¨ | å®‰å…¨æµ‹è¯• | å®‰å…¨æœºåˆ¶æµ‹è¯• |
| ç”¨æˆ·éªŒæ”¶ | ç¬¬5å‘¨ | UAT | ç”¨æˆ·åœºæ™¯æµ‹è¯• |

#### 3.2 æµ‹è¯•æ ‡å‡†
- **åŠŸèƒ½æµ‹è¯•**: æ‰€æœ‰åŠŸèƒ½ç‚¹100%é€šè¿‡
- **æ€§èƒ½æµ‹è¯•**: å“åº”æ—¶é—´ < 100msï¼ˆ90%çš„è¯·æ±‚ï¼‰
- **ç¨³å®šæ€§æµ‹è¯•**: 24å°æ—¶æ— æ•…éšœè¿è¡Œ
- **å®‰å…¨æµ‹è¯•**: æ— é«˜å±å®‰å…¨æ¼æ´

## ğŸ“Š æˆåŠŸæ ‡å‡†å’ŒéªŒæ”¶æ ‡å‡†

### 1. æŠ€æœ¯æˆåŠŸæ ‡å‡†

#### 1.1 æ•°æ®å®Œæ•´æ€§
- **æ•°æ®å®Œæ•´æ€§**: 100%çš„æ•°æ®æˆåŠŸè¿ç§»ï¼Œæ— æ•°æ®ä¸¢å¤±
- **æ•°æ®ä¸€è‡´æ€§**: è¿ç§»å‰åæ•°æ®å®Œå…¨ä¸€è‡´
- **å…³ç³»å®Œæ•´æ€§**: æ‰€æœ‰æ•°æ®å…³ç³»ä¿æŒæ­£ç¡®
- **æ ¼å¼æ­£ç¡®æ€§**: æ‰€æœ‰æ•°æ®æ ¼å¼ç¬¦åˆæ–°æ¶æ„è¦æ±‚

#### 1.2 æ€§èƒ½æŒ‡æ ‡
- **æŸ¥è¯¢æ€§èƒ½**: æŸ¥è¯¢å“åº”æ—¶é—´æå‡30%ä»¥ä¸Š
- **å­˜å‚¨æ•ˆç‡**: å­˜å‚¨ç©ºé—´ä½¿ç”¨ä¼˜åŒ–20%ä»¥ä¸Š
- **å¹¶å‘æ€§èƒ½**: æ”¯æŒ100+å¹¶å‘ç”¨æˆ·
- **ç³»ç»Ÿç¨³å®šæ€§**: 99.9%ä»¥ä¸Šçš„å¯ç”¨æ€§

#### 1.3 åŠŸèƒ½è¦æ±‚
- **å‘åå…¼å®¹**: 100%çš„ç°æœ‰APIä¿æŒå…¼å®¹
- **æ–°åŠŸèƒ½**: æ‰€æœ‰æ–°åŠŸèƒ½æ­£å¸¸è¿è¡Œ
- **ç”¨æˆ·ä½“éªŒ**: ç”¨æˆ·æ»¡æ„åº¦ > 90%
- **é”™è¯¯ç‡**: ç³»ç»Ÿé”™è¯¯ç‡ < 0.1%

### 2. ä¸šåŠ¡æˆåŠŸæ ‡å‡†

#### 2.1 ä¸šåŠ¡è¿ç»­æ€§
- **é›¶åœæœº**: è¿ç§»è¿‡ç¨‹ä¸­ä¸šåŠ¡ä¸ä¸­æ–­
- **ç”¨æˆ·ä½“éªŒ**: ç”¨æˆ·æ— æ„ŸçŸ¥è¿ç§»è¿‡ç¨‹
- **åŠŸèƒ½å¯ç”¨**: æ‰€æœ‰ä¸šåŠ¡åŠŸèƒ½æ­£å¸¸å¯ç”¨
- **æ€§èƒ½è¡¨ç°**: æ€§èƒ½ä¸ä¸‹é™æˆ–æœ‰æ‰€æå‡

#### 2.2 è¿ç»´è¦æ±‚
- **å¯ç»´æŠ¤æ€§**: ç³»ç»Ÿæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- **å¯ç›‘æ§æ€§**: å®Œæ•´çš„ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶
- **å¯æ¢å¤æ€§**: å¿«é€Ÿæ¢å¤å’Œæ•…éšœå¤„ç†èƒ½åŠ›
- **å¯æ‰©å±•æ€§**: æ”¯æŒæœªæ¥ä¸šåŠ¡æ‰©å±•

### 3. éªŒæ”¶æµç¨‹

#### 3.1 æŠ€æœ¯éªŒæ”¶
- **ä»£ç å®¡æŸ¥**: ä»£ç è´¨é‡ç¬¦åˆæ ‡å‡†
- **æµ‹è¯•æŠ¥å‘Š**: æ‰€æœ‰æµ‹è¯•é€šè¿‡
- **æ€§èƒ½æµ‹è¯•**: æ€§èƒ½æŒ‡æ ‡è¾¾æ ‡
- **å®‰å…¨æµ‹è¯•**: å®‰å…¨æ£€æŸ¥é€šè¿‡

#### 3.2 ä¸šåŠ¡éªŒæ”¶
- **åŠŸèƒ½éªŒè¯**: ä¸šåŠ¡åŠŸèƒ½éªŒè¯é€šè¿‡
- **ç”¨æˆ·éªŒæ”¶**: ç”¨æˆ·éªŒæ”¶æµ‹è¯•é€šè¿‡
- **æ€§èƒ½éªŒæ”¶**: æ€§èƒ½è¦æ±‚æ»¡è¶³
- **è¿ç»´éªŒæ”¶**: è¿ç»´è¦æ±‚æ»¡è¶³

## ğŸ“ æ€»ç»“å’Œåç»­è®¡åˆ’

### 1. é¡¹ç›®æ€»ç»“

æœ¬æ•°æ®è¿ç§»ç­–ç•¥æ–‡æ¡£ä¸ºCardEverythingé¡¹ç›®æä¾›äº†ä»ç°æœ‰æ•°æ®åº“æ¶æ„åˆ°ç»Ÿä¸€æ¶æ„çš„å®Œæ•´è¿ç§»æ–¹æ¡ˆã€‚é€šè¿‡æ·±å…¥åˆ†æç°æœ‰æ¶æ„å·®å¼‚ã€è®¾è®¡ç»Ÿä¸€æ•°æ®æ¨¡å‹ã€åˆ¶å®šé›¶åœæœºè¿ç§»ç­–ç•¥ã€å®æ–½æ•°æ®å®‰å…¨ä¿éšœï¼Œä»¥åŠå»ºç«‹å®Œæ•´çš„ç›‘æ§å’ŒéªŒè¯æœºåˆ¶ï¼Œæˆ‘ä»¬ç¡®ä¿äº†è¿ç§»è¿‡ç¨‹çš„å®‰å…¨ã€é«˜æ•ˆå’Œå¯é ã€‚

### 2. å…³é”®æˆåŠŸå› ç´ 

#### 2.1 æŠ€æœ¯å› ç´ 
- **å……åˆ†çš„å‰æœŸåˆ†æ**: æ·±å…¥ç†è§£ç°æœ‰æ¶æ„å’Œæ•°æ®ä¾èµ–
- **åˆç†çš„è®¾è®¡æ–¹æ¡ˆ**: ç»Ÿä¸€çš„æ•°æ®æ¨¡å‹å’Œè¿ç§»ç­–ç•¥
- **å®Œå–„çš„å·¥å…·æ”¯æŒ**: è‡ªåŠ¨åŒ–çš„è¿ç§»å’ŒéªŒè¯å·¥å…·
- **å…¨é¢çš„æµ‹è¯•è¦†ç›–**: å¤šå±‚æ¬¡çš„æµ‹è¯•éªŒè¯

#### 2.2 ç®¡ç†å› ç´ 
- **æ˜ç¡®çš„é¡¹ç›®è®¡åˆ’**: æ¸…æ™°çš„é‡Œç¨‹ç¢‘å’Œäº¤ä»˜ç‰©
- **ä¸“ä¸šçš„å›¢é˜Ÿé…ç½®**: åˆç†çš„æŠ€èƒ½ç»„åˆå’Œè´£ä»»åˆ†å·¥
- **æœ‰æ•ˆçš„é£é™©ç®¡ç†**: è¯†åˆ«å’Œç¼“è§£æ½œåœ¨é£é™©
- **å……åˆ†çš„æ²Ÿé€šåè°ƒ**: å„æ–¹åˆ©ç›Šç›¸å…³è€…çš„æœ‰æ•ˆæ²Ÿé€š

### 3. åç»­ä¼˜åŒ–è®¡åˆ’

#### 3.1 çŸ­æœŸä¼˜åŒ–ï¼ˆ1-3ä¸ªæœˆï¼‰
- **æ€§èƒ½è°ƒä¼˜**: åŸºäºå®é™…ä½¿ç”¨æ•°æ®è¿›è¡Œæ€§èƒ½ä¼˜åŒ–
- **ç›‘æ§å®Œå–„**: å¢å¼ºç›‘æ§å‘Šè­¦æœºåˆ¶
- **æ–‡æ¡£æ›´æ–°**: æ ¹æ®å®é™…è¿è¡Œæƒ…å†µæ›´æ–°æ–‡æ¡£
- **çŸ¥è¯†è½¬ç§»**: å›¢é˜ŸæŠ€èƒ½æå‡å’ŒçŸ¥è¯†å…±äº«

#### 3.2 ä¸­æœŸå‘å±•ï¼ˆ3-6ä¸ªæœˆï¼‰
- **åŠŸèƒ½æ‰©å±•**: åŸºäºæ–°æ¶æ„å¼€å‘æ–°åŠŸèƒ½
- **æ€§èƒ½ä¼˜åŒ–**: æŒç»­çš„æ€§èƒ½ä¼˜åŒ–å’Œæ”¹è¿›
- **ç”¨æˆ·ä½“éªŒ**: åŸºäºç”¨æˆ·åé¦ˆæ”¹è¿›ç³»ç»Ÿ
- **è¿ç»´è‡ªåŠ¨åŒ–**: å¢å¼ºè‡ªåŠ¨åŒ–è¿ç»´èƒ½åŠ›

#### 3.3 é•¿æœŸè§„åˆ’ï¼ˆ6-12ä¸ªæœˆï¼‰
- **æ¶æ„æ¼”è¿›**: æ ¹æ®ä¸šåŠ¡å‘å±•ä¼˜åŒ–æ¶æ„
- **æŠ€æœ¯å‡çº§**: è·Ÿè¿›æ–°æŠ€æœ¯å‘å±•è¿›è¡ŒæŠ€æœ¯å‡çº§
- **ç”Ÿæ€å»ºè®¾**: æ„å»ºå®Œæ•´çš„æŠ€æœ¯ç”Ÿæ€
- **æœ€ä½³å®è·µ**: å½¢æˆå¯å¤ç”¨çš„æœ€ä½³å®è·µ

### 4. ç»éªŒæ•™è®­å’Œæ”¹è¿›å»ºè®®

#### 4.1 ç»éªŒæ€»ç»“
- **é‡è§†å‰æœŸè§„åˆ’**: å……åˆ†çš„å‰æœŸè§„åˆ’æ˜¯é¡¹ç›®æˆåŠŸçš„åŸºç¡€
- **å¼ºè°ƒè´¨é‡æ§åˆ¶**: å…¨ç¨‹çš„è´¨é‡æ§åˆ¶ç¡®ä¿é¡¹ç›®è´¨é‡
- **å…³æ³¨ç”¨æˆ·ä½“éªŒ**: å§‹ç»ˆä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒè¿›è¡Œè®¾è®¡å’Œå¼€å‘
- **æŒç»­æ”¹è¿›**: é¡¹ç›®å®Œæˆåçš„æŒç»­æ”¹è¿›å¾ˆé‡è¦

#### 4.2 æ”¹è¿›å»ºè®®
- **å¢å¼ºè‡ªåŠ¨åŒ–**: è¿›ä¸€æ­¥æé«˜è‡ªåŠ¨åŒ–ç¨‹åº¦
- **å®Œå–„ç›‘æ§**: å»ºç«‹æ›´å…¨é¢çš„ç›‘æ§ä½“ç³»
- **æ ‡å‡†åŒ–æµç¨‹**: å»ºç«‹æ ‡å‡†åŒ–çš„å¼€å‘å’Œè¿ç»´æµç¨‹
- **çŸ¥è¯†ç®¡ç†**: åŠ å¼ºçŸ¥è¯†ç®¡ç†å’Œæ–‡æ¡£å»ºè®¾

## âš ï¸ é£é™©è¯„ä¼°å’Œç¼“è§£æªæ–½

### 1. é£é™©è¯†åˆ«çŸ©é˜µ

åŸºäºW1-T008ä»»åŠ¡è¦æ±‚ï¼Œæˆ‘ä»¬å¯¹æ•°æ®è¿ç§»è¿‡ç¨‹ä¸­çš„ä¸»è¦é£é™©è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼š

| é£é™©ç±»åˆ« | é£é™©æè¿° | å½±å“ç¨‹åº¦ | å‘ç”Ÿæ¦‚ç‡ | é£é™©ç­‰çº§ | ç¼“è§£æªæ–½ |
|----------|----------|----------|----------|----------|----------|
| **æ•°æ®ä¸€è‡´æ€§é£é™©** | è¿ç§»è¿‡ç¨‹ä¸­å¯èƒ½å¯¼è‡´æ•°æ®ä¸¢å¤±æˆ–ä¸ä¸€è‡´ | ğŸ”´ é«˜ | ğŸŸ¡ ä¸­ç­‰ | ğŸ”´ é«˜é£é™© | å¼ºäº‹åŠ¡æ€§è¿ç§»ï¼Œå®æ—¶ä¸€è‡´æ€§æ£€æŸ¥ï¼Œè‡ªåŠ¨ä¿®å¤æœºåˆ¶ |
| **æœåŠ¡ä¸­æ–­é£é™©** | è¿ç§»è¿‡ç¨‹å¯èƒ½å½±å“ç”¨æˆ·ä½“éªŒ | ğŸŸ¡ ä¸­ç­‰ | ğŸŸ¢ ä½ | ğŸŸ¡ ä¸­é£é™© | é›¶åœæœºè¿ç§»ï¼Œæ¸è¿›å¼éƒ¨ç½²ï¼Œç°åº¦å‘å¸ƒ |
| **æ€§èƒ½ä¸‹é™é£é™©** | è¿ç§»æœŸé—´ç³»ç»Ÿæ€§èƒ½å¯èƒ½æš‚æ—¶ä¸‹é™ | ğŸŸ¡ ä¸­ç­‰ | ğŸŸ¡ ä¸­ç­‰ | ğŸŸ¡ ä¸­é£é™© | æ€§èƒ½ç›‘æ§ï¼Œè‡ªé€‚åº”ä¼˜åŒ–ï¼Œèµ„æºåŠ¨æ€è°ƒé… |
| **å…¼å®¹æ€§é£é™©** | APIå˜æ›´å¯èƒ½å¯¼è‡´ç°æœ‰ç»„ä»¶ä¸å…¼å®¹ | ğŸ”´ é«˜ | ğŸŸ¢ ä½ | ğŸŸ¡ ä¸­é£é™© | APIå…¼å®¹å±‚ï¼Œå……åˆ†æµ‹è¯•ï¼Œå›æ»šæœºåˆ¶ |
| **å®‰å…¨é£é™©** | æ•°æ®è¿ç§»è¿‡ç¨‹ä¸­çš„æ•°æ®å®‰å…¨é—®é¢˜ | ğŸ”´ é«˜ | ğŸŸ¢ ä½ | ğŸŸ¡ ä¸­é£é™© | åŠ å¯†ä¼ è¾“ï¼Œæƒé™æ§åˆ¶ï¼Œå®¡è®¡æ—¥å¿— |

### 2. å…³é”®é£é™©ç¼“è§£ç­–ç•¥

#### 2.1 æ•°æ®å®‰å…¨ä¿éšœæªæ–½
```typescript
// æ•°æ®å®‰å…¨ä¿éšœç³»ç»Ÿ
export class DataSecurityGuardian {
  async ensureDataSecurity(): Promise<SecurityStatus> {
    const measures = [
      {
        type: 'encryption',
        description: 'è¿ç§»æ•°æ®å…¨ç¨‹åŠ å¯†',
        status: await this.validateEncryptionEnabled()
      },
      {
        type: 'backup',
        description: 'å®Œæ•´æ•°æ®å¤‡ä»½',
        status: await this.validateBackupIntegrity()
      },
      {
        type: 'access_control',
        description: 'ä¸¥æ ¼çš„è®¿é—®æ§åˆ¶',
        status: await this.validateAccessControl()
      },
      {
        type: 'audit_trail',
        description: 'å®Œæ•´å®¡è®¡æ—¥å¿—',
        status: await this.validateAuditTrail()
      }
    ]

    return {
      overallSecurity: measures.every(m => m.status),
      measures,
      lastValidation: new Date()
    }
  }
}
```

#### 2.2 å›æ»šæœºåˆ¶å’Œåº”æ€¥é¢„æ¡ˆ
```typescript
// å›æ»šç®¡ç†ç³»ç»Ÿ
export class RollbackManagementSystem {
  async createMigrationCheckpoint(): Promise<MigrationCheckpoint> {
    const checkpoint: MigrationCheckpoint = {
      id: crypto.randomUUID(),
      timestamp: new Date(),
      databaseState: await this.captureDatabaseState(),
      apiState: await this.captureApiState(),
      userSessionState: await this.captureUserSessions(),
      metadata: {
        migrationVersion: '2.0.0',
        estimatedRollbackTime: '30ç§’',
        dataConsistencyGuaranteed: true
      }
    }

    await this.persistCheckpoint(checkpoint)
    return checkpoint
  }

  async rollbackToCheckpoint(checkpointId: string): Promise<RollbackResult> {
    const checkpoint = await this.loadCheckpoint(checkpointId)

    try {
      // 1. åœæ­¢æ‰€æœ‰åŒæ­¥æ“ä½œ
      await this.pauseAllSyncOperations()

      // 2. æ¢å¤æ•°æ®åº“çŠ¶æ€
      await this.restoreDatabaseState(checkpoint.databaseState)

      // 3. æ¢å¤APIçŠ¶æ€
      await this.restoreApiState(checkpoint.apiState)

      // 4. æ¢å¤ç”¨æˆ·ä¼šè¯
      await this.restoreUserSessions(checkpoint.userSessionState)

      // 5. éªŒè¯æ¢å¤ç»“æœ
      const validationResult = await this.validateRollbackResult(checkpoint)

      return {
        success: validationResult.success,
        rollbackTime: Date.now() - checkpoint.timestamp.getTime(),
        dataConsistency: validationResult.dataConsistency,
        userImpact: 'minimal'
      }
    } catch (error) {
      // ç´§æ€¥æ¢å¤æªæ–½
      await this.emergencyRestore()
      throw error
    }
  }
}
```

### 3. ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ

#### 3.1 å®æ—¶ç›‘æ§ä»ªè¡¨æ¿
```typescript
// è¿ç§»ç›‘æ§ä¸­å¿ƒ
export class MigrationMonitoringCenter {
  async createRealTimeDashboard(): Promise<MonitoringDashboard> {
    return {
      // æ•°æ®ä¸€è‡´æ€§ç›‘æ§
      consistency: {
        localVsCloud: await this.checkLocalCloudConsistency(),
        entityIntegrity: await this.checkEntityIntegrity(),
        relationshipIntegrity: await this.checkRelationshipIntegrity()
      },

      // æ€§èƒ½ç›‘æ§
      performance: {
        syncLatency: await this.measureSyncLatency(),
        memoryUsage: await this.measureMemoryUsage(),
        cpuUsage: await this.measureCpuUsage(),
        networkThroughput: await this.measureNetworkThroughput()
      },

      // é”™è¯¯ç›‘æ§
      errors: {
        syncErrors: await this.getSyncErrors(),
        apiErrors: await this.getApiErrors(),
        databaseErrors: await this.getDatabaseErrors()
      },

      // ç”¨æˆ·å½±å“ç›‘æ§
      userImpact: {
        activeUsers: await this.getActiveUserCount(),
        affectedUsers: await this.getAffectedUserCount(),
        userSatisfaction: await this.getUserSatisfactionScore()
      }
    }
  }
}
```

#### 3.2 æ™ºèƒ½å‘Šè­¦ç³»ç»Ÿ
```typescript
// æ™ºèƒ½å‘Šè­¦å¼•æ“
export class IntelligentAlertEngine {
  async analyzeAndAlert(): Promise<Alert[]> {
    const alerts = []

    // åˆ†ææ€§èƒ½æŒ‡æ ‡
    const performanceMetrics = await this.collectPerformanceMetrics()
    if (performanceMetrics.syncLatency > 200) {
      alerts.push({
        type: 'performance_degradation',
        severity: 'warning',
        message: 'åŒæ­¥å»¶è¿Ÿè¶…è¿‡200msï¼Œå¯èƒ½å½±å“ç”¨æˆ·ä½“éªŒ',
        recommendation: 'æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒæœåŠ¡å™¨è´Ÿè½½',
        autoMitigation: 'enable_optimized_mode'
      })
    }

    // åˆ†ææ•°æ®ä¸€è‡´æ€§
    const consistencyMetrics = await this.collectConsistencyMetrics()
    if (consistencyMetrics.inconsistencyRate > 0.05) {
      alerts.push({
        type: 'data_inconsistency',
        severity: 'critical',
        message: 'æ•°æ®ä¸ä¸€è‡´ç‡è¶…è¿‡5%ï¼Œéœ€è¦ç«‹å³å¤„ç†',
        recommendation: 'å¯åŠ¨æ•°æ®ä¿®å¤æµç¨‹',
        autoMitigation: 'initiate_auto_repair'
      })
    }

    // åˆ†æé”™è¯¯ç‡
    const errorMetrics = await this.collectErrorMetrics()
    if (errorMetrics.errorRate > 0.1) {
      alerts.push({
        type: 'high_error_rate',
        severity: 'critical',
        message: 'é”™è¯¯ç‡è¶…è¿‡10%ï¼Œç³»ç»Ÿç¨³å®šæ€§å—åˆ°å½±å“',
        recommendation: 'æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—å’Œé”™è¯¯æ¨¡å¼',
        autoMitigation: 'enable_fallback_mode'
      })
    }

    return alerts
  }
}
```

## ğŸ“… å…·ä½“å®æ–½è®¡åˆ’ï¼ˆW1-T008ä»»åŠ¡äº¤ä»˜ï¼‰

### ç¬¬1å‘¨ï¼šå‡†å¤‡å’Œè§„åˆ’é˜¶æ®µ (2025-01-13 - 2025-01-19)

#### W1-T008 ä»»åŠ¡åˆ†è§£
**æœ¬å‘¨ç›®æ ‡**: å®Œæˆæ•°æ®è¿ç§»ç­–ç•¥çš„åˆ¶å®šå’ŒåŸºç¡€è®¾æ–½å‡†å¤‡

| å­ä»»åŠ¡ | è´Ÿè´£äºº | çŠ¶æ€ | ä¼˜å…ˆçº§ | é¢„è®¡å·¥æ—¶ | äº¤ä»˜ç‰© |
|--------|--------|------|--------|----------|--------|
| W1-T008.1 | å®Œæˆç°æœ‰æ•°æ®æ¶æ„åˆ†æ | Database-Architect | âœ… COMPLETED | ğŸ”´ é«˜ | 6h | æ¶æ„åˆ†ææŠ¥å‘Š |
| W1-T008.2 | è®¾è®¡ç»Ÿä¸€æ•°æ®è¿ç§»ç­–ç•¥ | Database-Architect | âœ… COMPLETED | ğŸ”´ é«˜ | 8h | è¿ç§»ç­–ç•¥æ–‡æ¡£ |
| W1-T008.3 | åˆ¶å®šé£é™©è¯„ä¼°å’Œç¼“è§£æªæ–½ | Database-Architect | âœ… COMPLETED | ğŸ”´ é«˜ | 4h | é£é™©è¯„ä¼°æŠ¥å‘Š |
| W1-T008.4 | åˆ›å»ºè¿ç§»å·¥å…·å’Œè„šæœ¬ | Database-Architect | ğŸŸ¡ IN_PROGRESS | ğŸŸ¡ ä¸­ | 6h | è¿ç§»å·¥å…·åŒ… |
| W1-T008.5 | å»ºç«‹ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ | Database-Architect | âšª AWAITING | ğŸŸ¡ ä¸­ | 4h | ç›‘æ§ç³»ç»Ÿ |

### ç¬¬2-3å‘¨ï¼šå®æ–½é˜¶æ®µ (2025-01-20 - 2025-02-02)

#### é˜¶æ®µ2.1ï¼šå…¼å®¹å±‚éƒ¨ç½² (Week 2)
- [ ] éƒ¨ç½²APIå…¼å®¹å±‚
- [ ] é…ç½®è¿‡æ¸¡æ¨¡å¼
- [ ] æ‰§è¡Œå…¼å®¹æ€§æµ‹è¯•
- [ ] ç›‘æ§ç³»ç»Ÿè¡¨ç°

#### é˜¶æ®µ2.2ï¼šæ•°æ®ç»Ÿä¸€è¿ç§» (Week 3)
- [ ] IndexedDB Schemaå‡çº§
- [ ] Supabaseæ•°æ®åŒæ­¥
- [ ] æ•°æ®ä¸€è‡´æ€§éªŒè¯
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

### ç¬¬4-6å‘¨ï¼šä¼˜åŒ–å’Œç¨³å®šé˜¶æ®µ (2025-02-03 - 2025-02-24)

#### é˜¶æ®µ3.1ï¼šæ€§èƒ½ä¼˜åŒ– (Week 4-5)
- [ ] å®ç°æ™ºèƒ½ç¼“å­˜æœºåˆ¶
- [ ] ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
- [ ] ç½‘ç»œè¯·æ±‚ä¼˜åŒ–
- [ ] å†…å­˜ä½¿ç”¨ä¼˜åŒ–

#### é˜¶æ®µ3.2ï¼šç³»ç»Ÿç¨³å®šåŒ– (Week 6)
- [ ] å…¨é¢æµ‹è¯•éªŒè¯
- [ ] ç°åº¦å‘å¸ƒå‡†å¤‡
- [ ] ç”¨æˆ·éªŒæ”¶æµ‹è¯•
- [ ] æ­£å¼å‘å¸ƒå‡†å¤‡

### æˆåŠŸæ ‡å‡†å’ŒéªŒæ”¶æŒ‡æ ‡

#### æŠ€æœ¯æŒ‡æ ‡
- **æ•°æ®ä¸€è‡´æ€§**: 99.9%çš„æ•°æ®åœ¨è¿ç§»åä¿æŒå®Œå…¨ä¸€è‡´
- **ç³»ç»Ÿå¯ç”¨æ€§**: è¿ç§»è¿‡ç¨‹ä¸­ç³»ç»Ÿå¯ç”¨æ€§â‰¥99.5%
- **æ€§èƒ½æå‡**: è¿ç§»å®ŒæˆååŒæ­¥æ€§èƒ½æå‡70-80%
- **é›¶æ•°æ®ä¸¢å¤±**: ç¡®ä¿è¿ç§»è¿‡ç¨‹ä¸­æ— æ•°æ®ä¸¢å¤±
- **å›æ»šæ—¶é—´**: ç´§æ€¥å›æ»šæ—¶é—´â‰¤30ç§’

#### ä¸šåŠ¡æŒ‡æ ‡
- **ç”¨æˆ·ä½“éªŒ**: è¿ç§»è¿‡ç¨‹ä¸­ç”¨æˆ·æ„ŸçŸ¥åº¦â‰¤5%
- **åŠŸèƒ½å®Œæ•´æ€§**: æ‰€æœ‰ç°æœ‰åŠŸèƒ½åœ¨è¿ç§»å100%å¯ç”¨
- **å…¼å®¹æ€§**: ç°æœ‰UIç»„ä»¶æ— éœ€ä¿®æ”¹å³å¯ä½¿ç”¨æ–°æ¶æ„
- **å“åº”æ—¶é—´**: å¹³å‡å“åº”æ—¶é—´â‰¤100ms
- **é”™è¯¯ç‡**: ç³»ç»Ÿé”™è¯¯ç‡â‰¤0.1%

---

## ğŸ“š é™„å½•

### A. æœ¯è¯­è¡¨
- **IndexedDB**: æµè§ˆå™¨ç«¯NoSQLæ•°æ®åº“
- **Dexie**: IndexedDBçš„JavaScriptåº“
- **è¿ç§»ç­–ç•¥**: æ•°æ®è¿ç§»çš„æ€»ä½“æ–¹æ¡ˆå’Œå®æ–½è®¡åˆ’
- **é›¶åœæœºè¿ç§»**: åœ¨ä¸å½±å“ä¸šåŠ¡è¿è¡Œçš„æƒ…å†µä¸‹è¿›è¡Œæ•°æ®è¿ç§»
- **æ•°æ®ä¸€è‡´æ€§**: æ•°æ®åœ¨ä¸åŒæ—¶åˆ»æˆ–ä¸åŒä½ç½®ä¿æŒä¸€è‡´çš„çŠ¶æ€
- **äº‹åŠ¡æ€§è¿ç§»**: ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡ç¡®ä¿è¿ç§»è¿‡ç¨‹çš„åŸå­æ€§
- **å›æ»šæœºåˆ¶**: åœ¨è¿ç§»å¤±è´¥æ—¶æ¢å¤åˆ°åŸå§‹çŠ¶æ€çš„èƒ½åŠ›

### B. å‚è€ƒæ–‡æ¡£
- [Dexie.js Documentation](https://dexie.org/)
- [IndexedDB API Reference](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API)
- [TypeScript Documentation](https://www.typescriptlang.org/docs/)
- [Database Migration Best Practices](https://www.oreilly.com/library/view/database-migration-best/9781492076876/)

### C. è”ç³»ä¿¡æ¯
- **é¡¹ç›®è´Ÿè´£äºº**: Database-Architect
- **æŠ€æœ¯æ”¯æŒ**: development@cardeverything.com
- **è¿ç»´æ”¯æŒ**: ops@cardeverything.com
- **æ–‡æ¡£ç»´æŠ¤**: docs@cardeverything.com

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0
**æœ€åæ›´æ–°**: 2025-01-13
**æ–‡æ¡£çŠ¶æ€**: W1-T008ä»»åŠ¡å·²å®Œæˆ
**ä»»åŠ¡çŠ¶æ€**: âœ… æ•°æ®è¿ç§»ç­–ç•¥å·²åˆ¶å®šå®Œæˆ
**ä¸‹æ¬¡æ›´æ–°**: æ ¹æ®ç¬¬2å‘¨å®æ–½è¿›å±•æ›´æ–°
**è´Ÿè´£äºº**: Database-Architect